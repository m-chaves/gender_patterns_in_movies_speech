{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 36,
     "status": "ok",
     "timestamp": 1642361175331,
     "user": {
      "displayName": "Mariana Chaves",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GitK6a8J23ZNS4lannJlrPyUTG-wmSWzMTrridp7OI=s64",
      "userId": "14956690162580527944"
     },
     "user_tz": -60
    },
    "id": "KGU7rAmNfmjF"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /nfshome/students/cm007951/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import argparse\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "import myfunctions\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "sys.path.append('../src/protoryNet/')\n",
    "from protoryNet import ProtoryNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/nfshome/students/cm007951/protorynet\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6IkGwcJaN4f_"
   },
   "source": [
    "# Import datasets (original example of the hotel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>characterID</th>\n",
       "      <th>movieID</th>\n",
       "      <th>character_name</th>\n",
       "      <th>gender</th>\n",
       "      <th>movie_title</th>\n",
       "      <th>movie_year</th>\n",
       "      <th>text_with_punctuation</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>F</td>\n",
       "      <td>10 things i hate about you</td>\n",
       "      <td>1999</td>\n",
       "      <td>They do not! I hope so. Let's go. Okay you're ...</td>\n",
       "      <td>They do not I hope so Lets go Okay youre gonna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>u100</td>\n",
       "      <td>m6</td>\n",
       "      <td>AMY</td>\n",
       "      <td>F</td>\n",
       "      <td>8mm</td>\n",
       "      <td>1999</td>\n",
       "      <td>She died in her sleep three days ago. It was i...</td>\n",
       "      <td>She died in her sleep three days ago It was in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>u1001</td>\n",
       "      <td>m65</td>\n",
       "      <td>PETE</td>\n",
       "      <td>M</td>\n",
       "      <td>from dusk till dawn</td>\n",
       "      <td>1996</td>\n",
       "      <td>Six-fifty. Knock yourself out. That's all that...</td>\n",
       "      <td>Sixfifty Knock yourself out Thats all thats be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>u1007</td>\n",
       "      <td>m66</td>\n",
       "      <td>BLONDELL</td>\n",
       "      <td>F</td>\n",
       "      <td>g.i. jane</td>\n",
       "      <td>1997</td>\n",
       "      <td>Wow Uh don't see it. There's no signature. But...</td>\n",
       "      <td>Wow Uh dont see it Theres no signature But han...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>u1008</td>\n",
       "      <td>m66</td>\n",
       "      <td>C.O.</td>\n",
       "      <td>M</td>\n",
       "      <td>g.i. jane</td>\n",
       "      <td>1997</td>\n",
       "      <td>Of course, but there's more Uh, V.I.P. securit...</td>\n",
       "      <td>Of course but theres more Uh VIP security arra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2399</th>\n",
       "      <td>2399</td>\n",
       "      <td>u983</td>\n",
       "      <td>m64</td>\n",
       "      <td>ALICE</td>\n",
       "      <td>F</td>\n",
       "      <td>friday the 13th</td>\n",
       "      <td>2009</td>\n",
       "      <td>Maybe we should wait for Mr. Christy. The kill...</td>\n",
       "      <td>Maybe we should wait for Mr Christy The killer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2400</th>\n",
       "      <td>2400</td>\n",
       "      <td>u985</td>\n",
       "      <td>m64</td>\n",
       "      <td>BILL</td>\n",
       "      <td>M</td>\n",
       "      <td>friday the 13th</td>\n",
       "      <td>2009</td>\n",
       "      <td>It's over twenty miles to the crossroads. Stev...</td>\n",
       "      <td>Its over twenty miles to the crossroads Stevel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2401</th>\n",
       "      <td>2401</td>\n",
       "      <td>u989</td>\n",
       "      <td>m64</td>\n",
       "      <td>MARCIE</td>\n",
       "      <td>F</td>\n",
       "      <td>friday the 13th</td>\n",
       "      <td>2009</td>\n",
       "      <td>Gotta pee. You're lying on my bladder. Like wa...</td>\n",
       "      <td>Gotta pee Youre lying on my bladder Like waves...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2402</th>\n",
       "      <td>2402</td>\n",
       "      <td>u993</td>\n",
       "      <td>m64</td>\n",
       "      <td>STEVE</td>\n",
       "      <td>M</td>\n",
       "      <td>friday the 13th</td>\n",
       "      <td>2009</td>\n",
       "      <td>I've got to go to town and pick up the trailer...</td>\n",
       "      <td>Ive got to go to town and pick up the trailer ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2403</th>\n",
       "      <td>2403</td>\n",
       "      <td>u998</td>\n",
       "      <td>m65</td>\n",
       "      <td>KATE</td>\n",
       "      <td>F</td>\n",
       "      <td>from dusk till dawn</td>\n",
       "      <td>1996</td>\n",
       "      <td>Everybody goes home! I'm going for 'em! I swea...</td>\n",
       "      <td>Everybody goes home Im going for em I swear to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2404 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0 characterID movieID character_name gender  \\\n",
       "0              0          u0      m0         BIANCA      F   \n",
       "1              1        u100      m6            AMY      F   \n",
       "2              2       u1001     m65           PETE      M   \n",
       "3              3       u1007     m66       BLONDELL      F   \n",
       "4              4       u1008     m66           C.O.      M   \n",
       "...          ...         ...     ...            ...    ...   \n",
       "2399        2399        u983     m64          ALICE      F   \n",
       "2400        2400        u985     m64           BILL      M   \n",
       "2401        2401        u989     m64         MARCIE      F   \n",
       "2402        2402        u993     m64          STEVE      M   \n",
       "2403        2403        u998     m65           KATE      F   \n",
       "\n",
       "                     movie_title movie_year  \\\n",
       "0     10 things i hate about you       1999   \n",
       "1                            8mm       1999   \n",
       "2            from dusk till dawn       1996   \n",
       "3                      g.i. jane       1997   \n",
       "4                      g.i. jane       1997   \n",
       "...                          ...        ...   \n",
       "2399             friday the 13th       2009   \n",
       "2400             friday the 13th       2009   \n",
       "2401             friday the 13th       2009   \n",
       "2402             friday the 13th       2009   \n",
       "2403         from dusk till dawn       1996   \n",
       "\n",
       "                                  text_with_punctuation  \\\n",
       "0     They do not! I hope so. Let's go. Okay you're ...   \n",
       "1     She died in her sleep three days ago. It was i...   \n",
       "2     Six-fifty. Knock yourself out. That's all that...   \n",
       "3     Wow Uh don't see it. There's no signature. But...   \n",
       "4     Of course, but there's more Uh, V.I.P. securit...   \n",
       "...                                                 ...   \n",
       "2399  Maybe we should wait for Mr. Christy. The kill...   \n",
       "2400  It's over twenty miles to the crossroads. Stev...   \n",
       "2401  Gotta pee. You're lying on my bladder. Like wa...   \n",
       "2402  I've got to go to town and pick up the trailer...   \n",
       "2403  Everybody goes home! I'm going for 'em! I swea...   \n",
       "\n",
       "                                                   text  \n",
       "0     They do not I hope so Lets go Okay youre gonna...  \n",
       "1     She died in her sleep three days ago It was in...  \n",
       "2     Sixfifty Knock yourself out Thats all thats be...  \n",
       "3     Wow Uh dont see it Theres no signature But han...  \n",
       "4     Of course but theres more Uh VIP security arra...  \n",
       "...                                                 ...  \n",
       "2399  Maybe we should wait for Mr Christy The killer...  \n",
       "2400  Its over twenty miles to the crossroads Stevel...  \n",
       "2401  Gotta pee Youre lying on my bladder Like waves...  \n",
       "2402  Ive got to go to town and pick up the trailer ...  \n",
       "2403  Everybody goes home Im going for em I swear to...  \n",
       "\n",
       "[2404 rows x 9 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cornell_prepro_characters = pd.read_csv('datasets/cornell_corpus/cornell_prepro_characters.csv')\n",
    "cornell_prepro_characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "myfunctions.protorynet_dataset_format(directory = 'datasets/cornell_corpus/cornell_prepro_characters/', \n",
    "                          df = cornell_prepro_characters, \n",
    "                          text_variable = 'text_with_punctuation', \n",
    "                          label_variable = 'gender', \n",
    "                          reference_label = 'F', \n",
    "                          return_sets = False, \n",
    "                          test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1642361179149,
     "user": {
      "displayName": "Mariana Chaves",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GitK6a8J23ZNS4lannJlrPyUTG-wmSWzMTrridp7OI=s64",
      "userId": "14956690162580527944"
     },
     "user_tz": -60
    },
    "id": "XqtOqokrfsBg"
   },
   "outputs": [],
   "source": [
    "dir = \"datasets/cornell_corpus/cornell_prepro_characters/\"\n",
    "with open (dir + 'y_train', 'rb') as fp:\n",
    "    y_train = pickle.load(fp)\n",
    "\n",
    "with open (dir + 'x_train', 'rb') as fp:\n",
    "    train_not_clean = pickle.load(fp)\n",
    "\n",
    "with open (dir + 'x_test', 'rb') as fp:\n",
    "    test_not_clean = pickle.load(fp)\n",
    "\n",
    "with open (dir + 'y_test', 'rb') as fp:\n",
    "    y_test = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xct3r6rdOLev"
   },
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 440,
     "status": "ok",
     "timestamp": 1642361184498,
     "user": {
      "displayName": "Mariana Chaves",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GitK6a8J23ZNS4lannJlrPyUTG-wmSWzMTrridp7OI=s64",
      "userId": "14956690162580527944"
     },
     "user_tz": -60
    },
    "id": "TEbpMg8ygFxV"
   },
   "outputs": [],
   "source": [
    "#this method is to split the paragraphs into sentences\n",
    "def gen_sents(para):\n",
    "    res = []\n",
    "    for p in para:\n",
    "#         sents = p.split(\".\")\n",
    "        sents = nltk.tokenize.sent_tokenize(p)\n",
    "        res.append(sents)\n",
    "    return res\n",
    "\n",
    "train_noclean_sents = gen_sents(train_not_clean)\n",
    "test_noclean_sents = gen_sents(test_not_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 276,
     "status": "ok",
     "timestamp": 1642361208493,
     "user": {
      "displayName": "Mariana Chaves",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GitK6a8J23ZNS4lannJlrPyUTG-wmSWzMTrridp7OI=s64",
      "userId": "14956690162580527944"
     },
     "user_tz": -60
    },
    "id": "nNM0Ud6CjIUw",
    "outputId": "eefbe444-b954-4520-c5f2-8e2650498247"
   },
   "outputs": [],
   "source": [
    "x_train = train_noclean_sents\n",
    "x_test = test_noclean_sents\n",
    "\n",
    "#optional: just to make sure the label values are integers\n",
    "y_train = [int(y) for y in y_train]\n",
    "y_test = [int(y) for y in y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16231,
     "status": "ok",
     "timestamp": 1642361275419,
     "user": {
      "displayName": "Mariana Chaves",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GitK6a8J23ZNS4lannJlrPyUTG-wmSWzMTrridp7OI=s64",
      "userId": "14956690162580527944"
     },
     "user_tz": -60
    },
    "id": "V7J7G3engGRo",
    "outputId": "a0023985-bbc3-4a5c-b1cf-58df4fe831cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module https://tfhub.dev/google/universal-sentence-encoder/4 loaded\n"
     ]
    }
   ],
   "source": [
    "#import Google Sentence encoder, to convert sentences into vector values\n",
    "module_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\"\n",
    "model_sentence_encoder = hub.load(module_url)\n",
    "print(\"module %s loaded\" % module_url)\n",
    "\n",
    "def embed(input):\n",
    "    return model_sentence_encoder(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a list of sentences\n",
    "sample_sentences = []\n",
    "for p in train_noclean_sents:\n",
    "    sample_sentences.extend(p)\n",
    "\n",
    "# We remove very long sentences since they behave as outliers.\n",
    "# Therefore when using k-medoids they become their own cluster. \n",
    "sample_sentences = [i for i in sample_sentences if len(i)>5 and len(i)<100]\n",
    "# Take 30000 sentences to initialize the prototypes\n",
    "# This step is done because k-medoids runs into memory issues when handleling too many samples\n",
    "sample_sentences = sample_sentences[:30000]    \n",
    "    \n",
    "#compute embeddings of sentences\n",
    "sample_sentences_embedded = embed(sample_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_prototypes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aWP5cKX6OQtu"
   },
   "source": [
    "# Prototype initialization with k-medoids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4698,
     "status": "ok",
     "timestamp": 1642361914768,
     "user": {
      "displayName": "Mariana Chaves",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GitK6a8J23ZNS4lannJlrPyUTG-wmSWzMTrridp7OI=s64",
      "userId": "14956690162580527944"
     },
     "user_tz": -60
    },
    "id": "-72NuWCJgKbf",
    "outputId": "6c9c5593-e62e-4fd8-a020-8dff66a90fc5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn_extra/cluster/_k_medoids.py:279: UserWarning: Cluster 5 is empty! self.labels_[self.medoid_indices_[5]] may not be labeled with its corresponding cluster (5).\n",
      "  \"its corresponding cluster ({k}).\".format(k=k)\n"
     ]
    }
   ],
   "source": [
    "# k_protos, vect_size = 10, 512 #512 because we have the sentences are transformed into vectors of size 512\n",
    "kmedoids = KMedoids(n_clusters = number_prototypes, random_state=0).fit(sample_sentences_embedded)\n",
    "k_cents = kmedoids.cluster_centers_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KI9aT_tZOY3Q"
   },
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "executionInfo": {
     "elapsed": 345,
     "status": "ok",
     "timestamp": 1642362244125,
     "user": {
      "displayName": "Mariana Chaves",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GitK6a8J23ZNS4lannJlrPyUTG-wmSWzMTrridp7OI=s64",
      "userId": "14956690162580527944"
     },
     "user_tz": -60
    },
    "id": "8NNK6ORKhtRV"
   },
   "outputs": [],
   "source": [
    "pNet = ProtoryNet() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4696,
     "status": "ok",
     "timestamp": 1642362251740,
     "user": {
      "displayName": "Mariana Chaves",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GitK6a8J23ZNS4lannJlrPyUTG-wmSWzMTrridp7OI=s64",
      "userId": "14956690162580527944"
     },
     "user_tz": -60
    },
    "id": "LOQ5g8igi7HW",
    "outputId": "95c6fdd6-167c-4580-9f91-26af08e158b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[db] model.input =  KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.string, name='input_6'), name='input_6', description=\"created by layer 'input_6'\")\n",
      "[db] protoLayerName =  proto_layer\n",
      "[db] protoLayer =  <protoryNet.ProtoryNet.createModel.<locals>.prototypeLayer object at 0x7f0345299f10>\n",
      "[db] protoLayer.output =  (<KerasTensor: shape=(1, None, 10) dtype=float32 (created by layer 'proto_layer')>, <KerasTensor: shape=(10, 512) dtype=float32 (created by layer 'proto_layer')>)\n",
      "[db] distanceLayer.output =  KerasTensor(type_spec=TensorSpec(shape=(1, None, 10), dtype=tf.float32, name=None), name='distance_layer/PartitionedCall:0', description=\"created by layer 'distance_layer'\")\n",
      "Model: \"custom_model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None,)]                 0         \n",
      "                                                                 \n",
      " keras_layer_5 (KerasLayer)  (None, 512)               256797824 \n",
      "                                                                 \n",
      " tf.expand_dims_5 (TFOpLambd  (1, None, 512)           0         \n",
      " a)                                                              \n",
      "                                                                 \n",
      " proto_layer (prototypeLayer  ((1, None, 10),          5120      \n",
      " )                            (10, 512))                         \n",
      "                                                                 \n",
      " distance_layer (distanceLay  (1, None, 10)            0         \n",
      " er)                                                             \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               [(1, None, 128),          71168     \n",
      "                              (1, 128),                          \n",
      "                              (1, 128)]                          \n",
      "                                                                 \n",
      " tf.__operators__.getitem_5   (1, 128)                 0         \n",
      " (SlicingOpLambda)                                               \n",
      "                                                                 \n",
      " dense_5 (Dense)             (1, 1)                    129       \n",
      "                                                                 \n",
      " tf.compat.v1.squeeze_5 (TFO  (1,)                     0         \n",
      " pLambda)                                                        \n",
      "                                                                 \n",
      " model_20 (Functional)       ((1, None, 10),           256802944 \n",
      "                              (10, 512))                         \n",
      "                                                                 \n",
      " model_21 (Functional)       (1, None, 10)             256802944 \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 256,874,241\n",
      "Trainable params: 256,874,241\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = pNet.createModel(k_cents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the initial prototypes produce repetitions. \n",
    "Later in the training the prototypes \"don't move\", they get stucked and this might be due to the poor initialization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: \"I'll never live as a thief!\",\n",
       " 1: \"I don't understand the allure of dehydrated food.\",\n",
       " 2: \"I don't understand the allure of dehydrated food.\",\n",
       " 3: 'I believe there was a conspiracy, but not the government.',\n",
       " 4: 'I believe there was a conspiracy, but not the government.',\n",
       " 5: 'I believe there was a conspiracy, but not the government.',\n",
       " 6: 'I believe there was a conspiracy, but not the government.',\n",
       " 7: \"I don't understand the allure of dehydrated food.\",\n",
       " 8: '\"Mister Crowley, what\\'s inside of your head \" We\\'re going to Jersey?',\n",
       " 9: \"I don't understand the allure of dehydrated food.\"}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prototypes = pNet.showPrototypes(sample_sentences, sample_sentences_embedded, nprototypes, printOutput=False, return_prototypes = True)\n",
    "prototypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8kiIGwFTqGEZ",
    "outputId": "842f8661-832d-4ed2-c1d5-e483a3132d1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0\n",
      "i =   0\n",
      "2/2 [==============================] - 12s 81ms/step - loss: 1.7885\n",
      "Evaluate on valid set:  0.5384615384615384\n",
      "This is the best eval res, saving the model...\n",
      "saving model now = 2022-07-21 16:18:19.346849\n",
      "just saved\n",
      "i =   50\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 0.2847\n",
      "i =   100\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.4844\n",
      "i =   150\n",
      "7/7 [==============================] - 1s 79ms/step - loss: 0.8454\n",
      "i =   200\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.5065\n",
      "Evaluate on valid set:  0.5384615384615384\n",
      "i =   250\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.6978\n",
      "i =   300\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 1.5081\n",
      "i =   350\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.3488\n",
      "i =   400\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 1.1628\n",
      "Evaluate on valid set:  0.5384615384615384\n",
      "i =   450\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 1.1679\n",
      "i =   500\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.9779\n",
      "i =   550\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.8228\n",
      "i =   600\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.9273\n",
      "Evaluate on valid set:  0.5384615384615384\n",
      "i =   650\n",
      "6/6 [==============================] - 0s 83ms/step - loss: 0.4005\n",
      "i =   700\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.8234\n",
      "i =   750\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.8507\n",
      "i =   800\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6681\n",
      "Evaluate on valid set:  0.5384615384615384\n",
      "i =   850\n",
      "7/7 [==============================] - 1s 82ms/step - loss: 1.1757\n",
      "i =   900\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.6551\n",
      "i =   950\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.4630\n",
      "i =   1000\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.9846\n",
      "Evaluate on valid set:  0.4594594594594595\n",
      "i =   1050\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3616\n",
      "i =   1100\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 0.9203\n",
      "i =   1150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.7295\n",
      "i =   1200\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.4781\n",
      "Evaluate on valid set:  0.5384615384615384\n",
      "i =   1250\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.9342\n",
      "i =   1300\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.5754\n",
      "i =   1350\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.6348\n",
      "i =   1400\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.4685\n",
      "Evaluate on valid set:  0.5384615384615384\n",
      "i =   1450\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.6988\n",
      "i =   1500\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 0.3141\n",
      "i =   1550\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.7071\n",
      "i =   1600\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.5344\n",
      "Evaluate on valid set:  0.5384615384615384\n",
      "i =   1650\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.9850\n",
      "i =   1700\n",
      "7/7 [==============================] - 1s 78ms/step - loss: 1.0530\n",
      "i =   1750\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.5396\n",
      "i =   1800\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.9738\n",
      "Evaluate on valid set:  0.5384615384615384\n",
      "i =   1850\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.7607\n",
      "i =   1900\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.8002\n",
      "21.75816112756729\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "pNet.train(x_train,y_train,x_test,y_test, epochs=1, saveModel=True, model_name=\"cornell_prepro_characters_1epoch_10proto\")\n",
    "execution_time = (time.time() - start_time) / 60\n",
    "print(execution_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model testing (from saved model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[db] model.input =  KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.string, name='input_8'), name='input_8', description=\"created by layer 'input_8'\")\n",
      "[db] protoLayerName =  proto_layer\n",
      "[db] protoLayer =  <protoryNet.ProtoryNet.createModel.<locals>.prototypeLayer object at 0x7f0230f92450>\n",
      "[db] protoLayer.output =  (<KerasTensor: shape=(1, None, 10) dtype=float32 (created by layer 'proto_layer')>, <KerasTensor: shape=(10, 512) dtype=float32 (created by layer 'proto_layer')>)\n",
      "[db] distanceLayer.output =  KerasTensor(type_spec=TensorSpec(shape=(1, None, 10), dtype=tf.float32, name=None), name='distance_layer/PartitionedCall:0', description=\"created by layer 'distance_layer'\")\n",
      "Model: \"custom_model_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_8 (InputLayer)        [(None,)]                 0         \n",
      "                                                                 \n",
      " keras_layer_7 (KerasLayer)  (None, 512)               256797824 \n",
      "                                                                 \n",
      " tf.expand_dims_7 (TFOpLambd  (1, None, 512)           0         \n",
      " a)                                                              \n",
      "                                                                 \n",
      " proto_layer (prototypeLayer  ((1, None, 10),          5120      \n",
      " )                            (10, 512))                         \n",
      "                                                                 \n",
      " distance_layer (distanceLay  (1, None, 10)            0         \n",
      " er)                                                             \n",
      "                                                                 \n",
      " lstm_7 (LSTM)               [(1, None, 128),          71168     \n",
      "                              (1, 128),                          \n",
      "                              (1, 128)]                          \n",
      "                                                                 \n",
      " tf.__operators__.getitem_7   (1, 128)                 0         \n",
      " (SlicingOpLambda)                                               \n",
      "                                                                 \n",
      " dense_7 (Dense)             (1, 1)                    129       \n",
      "                                                                 \n",
      " tf.compat.v1.squeeze_7 (TFO  (1,)                     0         \n",
      " pLambda)                                                        \n",
      "                                                                 \n",
      " model_28 (Functional)       ((1, None, 10),           256802944 \n",
      "                              (10, 512))                         \n",
      "                                                                 \n",
      " model_29 (Functional)       (1, None, 10)             256802944 \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 256,874,241\n",
      "Trainable params: 256,874,241\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nprototypes = 10\n",
    "model_path = 'cornell_prepro_characters_1epoch_10proto' + '.h5'\n",
    "\n",
    "pNet_saved = ProtoryNet()\n",
    "model = pNet_saved.createModel(np.zeros((nprototypes, 512)), nprototypes)\n",
    "model.load_weights(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sentences_embedded = pNet_saved.embed(sample_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The evaluation results state that everything should be classified as \"male speaker\", the test accuracy is low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.16879003,\n",
       "  0.1690114,\n",
       "  0.17131598,\n",
       "  0.1670248,\n",
       "  0.1720708,\n",
       "  0.16736056,\n",
       "  0.16735892,\n",
       "  0.16768745,\n",
       "  0.16962436,\n",
       "  0.16529681,\n",
       "  0.16732323,\n",
       "  0.16539885,\n",
       "  0.1772302,\n",
       "  0.17029823,\n",
       "  0.17064475,\n",
       "  0.17424919,\n",
       "  0.1658156,\n",
       "  0.1680691,\n",
       "  0.1672418,\n",
       "  0.1697042,\n",
       "  0.16963784,\n",
       "  0.16880204,\n",
       "  0.16838636,\n",
       "  0.16708624,\n",
       "  0.17060466,\n",
       "  0.16377603,\n",
       "  0.16790749,\n",
       "  0.17006014,\n",
       "  0.17070696,\n",
       "  0.1720554,\n",
       "  0.16768876,\n",
       "  0.16449663,\n",
       "  0.1716536,\n",
       "  0.1657432,\n",
       "  0.16846131,\n",
       "  0.16925485,\n",
       "  0.16597886,\n",
       "  0.17240399,\n",
       "  0.16415972,\n",
       "  0.17035015,\n",
       "  0.17562735,\n",
       "  0.16948648,\n",
       "  0.16914037,\n",
       "  0.17246786,\n",
       "  0.1700544,\n",
       "  0.16699113,\n",
       "  0.16964304,\n",
       "  0.16687196,\n",
       "  0.1683403,\n",
       "  0.17166764,\n",
       "  0.17375025,\n",
       "  0.17128104,\n",
       "  0.16944048,\n",
       "  0.1641847,\n",
       "  0.16845511,\n",
       "  0.16951805,\n",
       "  0.16427477,\n",
       "  0.17182611,\n",
       "  0.16751496,\n",
       "  0.16588496,\n",
       "  0.1632746,\n",
       "  0.16923879,\n",
       "  0.16346031,\n",
       "  0.1727642,\n",
       "  0.16724423,\n",
       "  0.16664238,\n",
       "  0.16605346,\n",
       "  0.16996521,\n",
       "  0.16535571,\n",
       "  0.17591824,\n",
       "  0.1658052,\n",
       "  0.16526477,\n",
       "  0.17029782,\n",
       "  0.1672427,\n",
       "  0.16447519,\n",
       "  0.16939056,\n",
       "  0.16963056,\n",
       "  0.17011258,\n",
       "  0.16980733,\n",
       "  0.16787946,\n",
       "  0.16759427,\n",
       "  0.16573662,\n",
       "  0.17088178,\n",
       "  0.16616522,\n",
       "  0.16491285,\n",
       "  0.16662844,\n",
       "  0.16460645,\n",
       "  0.16345678,\n",
       "  0.16982035,\n",
       "  0.16775651,\n",
       "  0.17129852,\n",
       "  0.16589159,\n",
       "  0.17111978,\n",
       "  0.16582505,\n",
       "  0.16578512,\n",
       "  0.16702783,\n",
       "  0.16608705,\n",
       "  0.1703378,\n",
       "  0.16558167,\n",
       "  0.16528049,\n",
       "  0.1692098,\n",
       "  0.16932379,\n",
       "  0.16919509,\n",
       "  0.16946535,\n",
       "  0.16667439,\n",
       "  0.17005499,\n",
       "  0.17258881,\n",
       "  0.16774926,\n",
       "  0.16977102,\n",
       "  0.16914187,\n",
       "  0.17171669,\n",
       "  0.16638638,\n",
       "  0.16900744,\n",
       "  0.17166963,\n",
       "  0.16660067,\n",
       "  0.17122854,\n",
       "  0.16626018,\n",
       "  0.17033526,\n",
       "  0.16785192,\n",
       "  0.17074831,\n",
       "  0.16842546,\n",
       "  0.16789548,\n",
       "  0.16655672,\n",
       "  0.16756444,\n",
       "  0.16964921,\n",
       "  0.16655,\n",
       "  0.17009258,\n",
       "  0.16680886,\n",
       "  0.16519183,\n",
       "  0.16782047,\n",
       "  0.1645604,\n",
       "  0.16563116,\n",
       "  0.17040636,\n",
       "  0.16714373,\n",
       "  0.16853586,\n",
       "  0.16521505,\n",
       "  0.17139111,\n",
       "  0.16572048,\n",
       "  0.16602185,\n",
       "  0.1645953,\n",
       "  0.17219865,\n",
       "  0.16473944,\n",
       "  0.17735122,\n",
       "  0.1683176,\n",
       "  0.16553567,\n",
       "  0.1726836,\n",
       "  0.1677222,\n",
       "  0.16611162,\n",
       "  0.16634421,\n",
       "  0.17069118,\n",
       "  0.16959973,\n",
       "  0.16515376,\n",
       "  0.16371576,\n",
       "  0.17381193,\n",
       "  0.16753264,\n",
       "  0.16900861,\n",
       "  0.16493385,\n",
       "  0.17297998,\n",
       "  0.1734714,\n",
       "  0.17238665,\n",
       "  0.16964786,\n",
       "  0.16633601,\n",
       "  0.16696446,\n",
       "  0.1665816,\n",
       "  0.17327169,\n",
       "  0.16611154,\n",
       "  0.17020501,\n",
       "  0.16673885,\n",
       "  0.16642971,\n",
       "  0.16626944,\n",
       "  0.16534153,\n",
       "  0.16760954,\n",
       "  0.16906548,\n",
       "  0.16840981,\n",
       "  0.16928633,\n",
       "  0.16509734,\n",
       "  0.16573857,\n",
       "  0.16465026,\n",
       "  0.16473237,\n",
       "  0.16570973,\n",
       "  0.16684657,\n",
       "  0.17068915,\n",
       "  0.17256072,\n",
       "  0.17458996,\n",
       "  0.16950837,\n",
       "  0.16602902,\n",
       "  0.17283912,\n",
       "  0.16975926,\n",
       "  0.16475184,\n",
       "  0.16787982,\n",
       "  0.16614975,\n",
       "  0.1681857,\n",
       "  0.17020613,\n",
       "  0.16701736,\n",
       "  0.16920108,\n",
       "  0.16637309,\n",
       "  0.16490705,\n",
       "  0.16605882,\n",
       "  0.16637982,\n",
       "  0.1773051,\n",
       "  0.17121245,\n",
       "  0.1648245,\n",
       "  0.16934541,\n",
       "  0.16391842,\n",
       "  0.16615933,\n",
       "  0.16480628,\n",
       "  0.16652343,\n",
       "  0.16816983,\n",
       "  0.16561846,\n",
       "  0.17331433,\n",
       "  0.16481309,\n",
       "  0.17092216,\n",
       "  0.17020218,\n",
       "  0.16860639,\n",
       "  0.16461538,\n",
       "  0.16901346,\n",
       "  0.17018662,\n",
       "  0.16651501,\n",
       "  0.16506751,\n",
       "  0.17168531,\n",
       "  0.16715945,\n",
       "  0.16571487,\n",
       "  0.17210026,\n",
       "  0.1699372,\n",
       "  0.16917889,\n",
       "  0.16920912,\n",
       "  0.17170008,\n",
       "  0.17593935,\n",
       "  0.16532846,\n",
       "  0.16290987,\n",
       "  0.16510068,\n",
       "  0.17088316,\n",
       "  0.1697769,\n",
       "  0.16188951,\n",
       "  0.1658102,\n",
       "  0.16952406,\n",
       "  0.165828,\n",
       "  0.16624588,\n",
       "  0.17224653,\n",
       "  0.16393659,\n",
       "  0.17282376,\n",
       "  0.16610186,\n",
       "  0.16487685,\n",
       "  0.16567972,\n",
       "  0.16907342,\n",
       "  0.16713542,\n",
       "  0.16426517,\n",
       "  0.16949357,\n",
       "  0.16758144,\n",
       "  0.16307613,\n",
       "  0.16383399,\n",
       "  0.16742928,\n",
       "  0.17208442,\n",
       "  0.16648261,\n",
       "  0.16845433,\n",
       "  0.16880724,\n",
       "  0.17047927,\n",
       "  0.16679779,\n",
       "  0.16921847,\n",
       "  0.16844791,\n",
       "  0.16627406,\n",
       "  0.16672303,\n",
       "  0.1694297,\n",
       "  0.17316626,\n",
       "  0.17425354,\n",
       "  0.16738266,\n",
       "  0.16388938,\n",
       "  0.17322484,\n",
       "  0.16674891,\n",
       "  0.16678195,\n",
       "  0.16735587,\n",
       "  0.16975562,\n",
       "  0.1688746,\n",
       "  0.16834001,\n",
       "  0.16608112,\n",
       "  0.16948839,\n",
       "  0.16635868,\n",
       "  0.16778396,\n",
       "  0.1699551,\n",
       "  0.17696673,\n",
       "  0.17448875,\n",
       "  0.1652655,\n",
       "  0.16729859,\n",
       "  0.1647682,\n",
       "  0.16916865,\n",
       "  0.16925448,\n",
       "  0.16680299,\n",
       "  0.16887583,\n",
       "  0.17100029,\n",
       "  0.16843554,\n",
       "  0.16440912,\n",
       "  0.16444278,\n",
       "  0.17222653,\n",
       "  0.16931926,\n",
       "  0.16816942,\n",
       "  0.16658622,\n",
       "  0.16800828,\n",
       "  0.16508847,\n",
       "  0.16899873,\n",
       "  0.16379325,\n",
       "  0.17866005,\n",
       "  0.16977875,\n",
       "  0.17028263,\n",
       "  0.16957039,\n",
       "  0.16387787,\n",
       "  0.16910918,\n",
       "  0.16816042,\n",
       "  0.16616319,\n",
       "  0.17192528,\n",
       "  0.16673668,\n",
       "  0.1706851,\n",
       "  0.16876963,\n",
       "  0.16853607,\n",
       "  0.16651635,\n",
       "  0.16754542,\n",
       "  0.16793455,\n",
       "  0.16588767,\n",
       "  0.1666165,\n",
       "  0.17108196,\n",
       "  0.17104907,\n",
       "  0.17042895,\n",
       "  0.16953374,\n",
       "  0.16460493,\n",
       "  0.1657836,\n",
       "  0.16622457,\n",
       "  0.17193665,\n",
       "  0.16576448,\n",
       "  0.17321755,\n",
       "  0.16882347,\n",
       "  0.16667835,\n",
       "  0.1653102,\n",
       "  0.17072198,\n",
       "  0.16789263,\n",
       "  0.16794385,\n",
       "  0.17201634,\n",
       "  0.16560303,\n",
       "  0.1667608,\n",
       "  0.17084917,\n",
       "  0.17326133,\n",
       "  0.1678813,\n",
       "  0.17048094,\n",
       "  0.17044947,\n",
       "  0.1689941,\n",
       "  0.1723177,\n",
       "  0.17312609,\n",
       "  0.16549183,\n",
       "  0.1650581,\n",
       "  0.16730689,\n",
       "  0.16743502,\n",
       "  0.16593373,\n",
       "  0.16611086,\n",
       "  0.17066333,\n",
       "  0.16803412,\n",
       "  0.17022394,\n",
       "  0.16576333,\n",
       "  0.16704832,\n",
       "  0.17283005,\n",
       "  0.16984661,\n",
       "  0.16453698,\n",
       "  0.16676694,\n",
       "  0.17233905,\n",
       "  0.16452122,\n",
       "  0.17511375,\n",
       "  0.17089601,\n",
       "  0.16798368,\n",
       "  0.1678744,\n",
       "  0.16368653,\n",
       "  0.16561696,\n",
       "  0.17171986,\n",
       "  0.1684487,\n",
       "  0.16410322,\n",
       "  0.16520447,\n",
       "  0.16434771,\n",
       "  0.17090493,\n",
       "  0.16713183,\n",
       "  0.16876936,\n",
       "  0.16350336,\n",
       "  0.17154495,\n",
       "  0.16878887,\n",
       "  0.16745721,\n",
       "  0.17077973,\n",
       "  0.17477025,\n",
       "  0.16426916,\n",
       "  0.16409032,\n",
       "  0.17264457,\n",
       "  0.17172746,\n",
       "  0.16956043,\n",
       "  0.16888984,\n",
       "  0.16563705,\n",
       "  0.1733982,\n",
       "  0.16876471,\n",
       "  0.16673315,\n",
       "  0.17007336,\n",
       "  0.16824883,\n",
       "  0.16648333,\n",
       "  0.16734906,\n",
       "  0.16598253,\n",
       "  0.1691138,\n",
       "  0.16748165,\n",
       "  0.16770066,\n",
       "  0.172145,\n",
       "  0.16573408,\n",
       "  0.1721932,\n",
       "  0.16639537,\n",
       "  0.16796839,\n",
       "  0.16925266,\n",
       "  0.17280081,\n",
       "  0.1655349,\n",
       "  0.16764776,\n",
       "  0.16571672,\n",
       "  0.17651595,\n",
       "  0.16708678,\n",
       "  0.16461863,\n",
       "  0.1668093,\n",
       "  0.16812849,\n",
       "  0.17637132,\n",
       "  0.16739415,\n",
       "  0.1669501,\n",
       "  0.16999848,\n",
       "  0.16772977,\n",
       "  0.17093912,\n",
       "  0.16884524,\n",
       "  0.17383045,\n",
       "  0.16934069,\n",
       "  0.16970985,\n",
       "  0.17321002,\n",
       "  0.16747814,\n",
       "  0.16548802,\n",
       "  0.16543235,\n",
       "  0.17052394,\n",
       "  0.16856088,\n",
       "  0.17290606,\n",
       "  0.1664708,\n",
       "  0.16883345,\n",
       "  0.16578536,\n",
       "  0.16444449,\n",
       "  0.1636293,\n",
       "  0.16920452,\n",
       "  0.16705291,\n",
       "  0.16801283,\n",
       "  0.1691113,\n",
       "  0.17165461,\n",
       "  0.168305,\n",
       "  0.17260218,\n",
       "  0.17035502,\n",
       "  0.1654915,\n",
       "  0.16638154,\n",
       "  0.17073657,\n",
       "  0.16943508,\n",
       "  0.17942862,\n",
       "  0.16624598,\n",
       "  0.16746628,\n",
       "  0.16482031,\n",
       "  0.17021924,\n",
       "  0.17160194,\n",
       "  0.16823068,\n",
       "  0.16973831,\n",
       "  0.16795424,\n",
       "  0.16653886,\n",
       "  0.1722443,\n",
       "  0.16690007,\n",
       "  0.17111695,\n",
       "  0.16380826,\n",
       "  0.16730623,\n",
       "  0.16867684,\n",
       "  0.16280085,\n",
       "  0.17217259,\n",
       "  0.16542496,\n",
       "  0.16571535,\n",
       "  0.16802387,\n",
       "  0.17171161,\n",
       "  0.1647441,\n",
       "  0.16859233,\n",
       "  0.16548799,\n",
       "  0.16709585,\n",
       "  0.16827425,\n",
       "  0.1720515,\n",
       "  0.16415583,\n",
       "  0.16651548,\n",
       "  0.16848943,\n",
       "  0.16439416],\n",
       " 0.5384615384615384)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pNet_saved.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prototypes are redundant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Heh heh heh.',\n",
       " 1: 'No, no.',\n",
       " 2: 'Oh no!',\n",
       " 3: 'Alright.',\n",
       " 4: 'Oh no.',\n",
       " 5: 'Oh yeah?',\n",
       " 6: 'Oh no.',\n",
       " 7: \"I'm sorry.\",\n",
       " 8: 'Oh no!',\n",
       " 9: 'Oh no.'}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prototypes = pNet_saved.showPrototypes(sample_sentences, sample_sentences_embedded, nprototypes, printOutput=False, return_prototypes = True)\n",
    "prototypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['My loyalty was never to my country.', 'Because it is my duty.', 'Yes, Mr. President.', \"That's affirmative.\", 'Roger.', 'Air Force One, acknowledged.', 'tNT.', 'EMERGENCY PARACHUTE LAUNCH RAMP.', 'About goddamn time.', 'Over the Black Sea.', 'I can probably get us to Turkey or Georgia.', 'Not even close.', \"Hell, we can't even make Syria or Iraq.\", \"We've stopped dumping but we've only got about twenty minutes of fuel left.\", 'Avionics compartment!', \"It's the only place.\", \"You better get Zedeck down there fast Unless, of course, you'd rather be a martyr than a savior.\", 'Well it worked.', 'why did they do that?', 'We checked the manifest.', 'Everyone was accounted for.', 'Nine.', 'Dead.', 'Sir, this plane carries the President of the United States.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.1690114], dtype=float32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testS = [\"I'm a women\",\n",
    "#          \"I was a waitress for 5 years\"]\n",
    "testS = x_test[1]\n",
    "print(testS)\n",
    "pNet_saved.predict(testS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['No, no.', 'Heh heh heh.', 'Oh yeah?', 'Oh yeah?', 'Alright.', 'No, no.', \"I'm sorry.\", \"I'm sorry.\", 'Heh heh heh.', 'Heh heh heh.', 'Heh heh heh.', 'No, no.', 'No, no.', 'Heh heh heh.', \"I'm sorry.\", 'Heh heh heh.', 'Heh heh heh.', 'Oh yeah?', 'Heh heh heh.', 'Heh heh heh.', 'Alright.', 'Alright.', 'Alright.', 'Heh heh heh.']\n"
     ]
    }
   ],
   "source": [
    "trajectory = pNet_saved.showTrajectory(testS, sample_sentences, sample_sentences_embedded)\n",
    "print(trajectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_trajectory(list_of_sentences):\n",
    "    '''\n",
    "    given a list of sentences (usually a list of prototypes), it returns the prediction for each of them\n",
    "    '''\n",
    "    pred = []\n",
    "    for prot in list_of_sentences:\n",
    "        pred.append(pNet_saved.predict([prot])[0])\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.17499548,\n",
       " 0.17575051,\n",
       " 0.17195183,\n",
       " 0.1776307,\n",
       " 0.17195183,\n",
       " 0.179942,\n",
       " 0.17195183,\n",
       " 0.17362915,\n",
       " 0.17195183,\n",
       " 0.17195183]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predictions for the prototypes\n",
    "score_trajectory(prototypes.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.17575051,\n",
       " 0.17499548,\n",
       " 0.179942,\n",
       " 0.179942,\n",
       " 0.1776307,\n",
       " 0.17575051,\n",
       " 0.17362915,\n",
       " 0.17362915,\n",
       " 0.17499548,\n",
       " 0.17499548,\n",
       " 0.17499548,\n",
       " 0.17575051,\n",
       " 0.17575051,\n",
       " 0.17499548,\n",
       " 0.17362915,\n",
       " 0.17499548,\n",
       " 0.17499548,\n",
       " 0.179942,\n",
       " 0.17499548,\n",
       " 0.17499548,\n",
       " 0.1776307,\n",
       " 0.1776307,\n",
       " 0.1776307,\n",
       " 0.17499548]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_trajectory(trajectory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note that all prototypes by their own would be classified as \"male\", that is, the prediction for each prototype would be \"male\".**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aWP5cKX6OQtu"
   },
   "source": [
    "# Prototype initialization at random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4698,
     "status": "ok",
     "timestamp": 1642361914768,
     "user": {
      "displayName": "Mariana Chaves",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GitK6a8J23ZNS4lannJlrPyUTG-wmSWzMTrridp7OI=s64",
      "userId": "14956690162580527944"
     },
     "user_tz": -60
    },
    "id": "-72NuWCJgKbf",
    "outputId": "6c9c5593-e62e-4fd8-a020-8dff66a90fc5"
   },
   "outputs": [],
   "source": [
    "# k_protos, vect_size = 10, 512 #512 because we have the sentences are transformed into vectors of size 512\n",
    "random_idx = np.random.choice(sample_sentences_embedded.shape[0], size = number_prototypes, replace=False)\n",
    "k_cents_random = np.array(sample_sentences_embedded)[random_idx, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KI9aT_tZOY3Q"
   },
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 345,
     "status": "ok",
     "timestamp": 1642362244125,
     "user": {
      "displayName": "Mariana Chaves",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GitK6a8J23ZNS4lannJlrPyUTG-wmSWzMTrridp7OI=s64",
      "userId": "14956690162580527944"
     },
     "user_tz": -60
    },
    "id": "8NNK6ORKhtRV"
   },
   "outputs": [],
   "source": [
    "pNet = ProtoryNet() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4696,
     "status": "ok",
     "timestamp": 1642362251740,
     "user": {
      "displayName": "Mariana Chaves",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GitK6a8J23ZNS4lannJlrPyUTG-wmSWzMTrridp7OI=s64",
      "userId": "14956690162580527944"
     },
     "user_tz": -60
    },
    "id": "LOQ5g8igi7HW",
    "outputId": "95c6fdd6-167c-4580-9f91-26af08e158b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[db] model.input =  KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.string, name='input_5'), name='input_5', description=\"created by layer 'input_5'\")\n",
      "[db] protoLayerName =  proto_layer\n",
      "[db] protoLayer =  <protoryNet.ProtoryNet.createModel.<locals>.prototypeLayer object at 0x7f3c0741d090>\n",
      "[db] protoLayer.output =  (<KerasTensor: shape=(1, None, 10) dtype=float32 (created by layer 'proto_layer')>, <KerasTensor: shape=(10, 512) dtype=float32 (created by layer 'proto_layer')>)\n",
      "[db] distanceLayer.output =  KerasTensor(type_spec=TensorSpec(shape=(1, None, 10), dtype=tf.float32, name=None), name='distance_layer/PartitionedCall:0', description=\"created by layer 'distance_layer'\")\n",
      "Model: \"custom_model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None,)]                 0         \n",
      "                                                                 \n",
      " keras_layer_4 (KerasLayer)  (None, 512)               256797824 \n",
      "                                                                 \n",
      " tf.expand_dims_4 (TFOpLambd  (1, None, 512)           0         \n",
      " a)                                                              \n",
      "                                                                 \n",
      " proto_layer (prototypeLayer  ((1, None, 10),          5120      \n",
      " )                            (10, 512))                         \n",
      "                                                                 \n",
      " distance_layer (distanceLay  (1, None, 10)            0         \n",
      " er)                                                             \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               [(1, None, 128),          71168     \n",
      "                              (1, 128),                          \n",
      "                              (1, 128)]                          \n",
      "                                                                 \n",
      " tf.__operators__.getitem_4   (1, 128)                 0         \n",
      " (SlicingOpLambda)                                               \n",
      "                                                                 \n",
      " dense_4 (Dense)             (1, 1)                    129       \n",
      "                                                                 \n",
      " tf.compat.v1.squeeze_4 (TFO  (1,)                     0         \n",
      " pLambda)                                                        \n",
      "                                                                 \n",
      " model_16 (Functional)       ((1, None, 10),           256802944 \n",
      "                              (10, 512))                         \n",
      "                                                                 \n",
      " model_17 (Functional)       (1, None, 10)             256802944 \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 256,874,241\n",
      "Trainable params: 256,874,241\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = pNet.createModel(k_cents_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With random selection it is less probable for prototypes to be the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Please will you believe me.',\n",
       " 1: \"Let them stay 'til morning.\",\n",
       " 2: \"So, how'd a shrink ever get to be a priest?\",\n",
       " 3: \"You can't ask me that!\",\n",
       " 4: \"Hi, I'm Steven.\",\n",
       " 5: 'You definitely do.',\n",
       " 6: 'On your piano, that is the swap.',\n",
       " 7: 'Books.',\n",
       " 8: 'Hello, Gabriel.',\n",
       " 9: 'Is this like your old convent?'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prototypes = pNet.showPrototypes(sample_sentences, sample_sentences_embedded, number_prototypes, printOutput=False, return_prototypes = True)\n",
    "prototypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8kiIGwFTqGEZ",
    "outputId": "842f8661-832d-4ed2-c1d5-e483a3132d1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0\n",
      "i =   0\n",
      "2/2 [==============================] - 10s 77ms/step - loss: 0.6798\n",
      "Evaluate on valid set:  0.4386694386694387\n",
      "This is the best eval res, saving the model...\n",
      "saving model now = 2022-07-25 14:46:35.345064\n",
      "just saved\n",
      "i =   50\n",
      "11/11 [==============================] - 1s 86ms/step - loss: 0.6108\n",
      "i =   100\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.7303\n",
      "i =   150\n",
      "7/7 [==============================] - 1s 82ms/step - loss: 0.6897\n",
      "i =   200\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.6855\n",
      "Evaluate on valid set:  0.5467775467775468\n",
      "This is the best eval res, saving the model...\n",
      "saving model now = 2022-07-25 14:49:18.078429\n",
      "just saved\n",
      "i =   250\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.4555\n",
      "i =   300\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.7954\n",
      "i =   350\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.5555\n",
      "i =   400\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.8365\n",
      "Evaluate on valid set:  0.5384615384615384\n",
      "i =   450\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 0.9471\n",
      "i =   500\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.7359\n",
      "i =   550\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.7614\n",
      "i =   600\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.7787\n",
      "Evaluate on valid set:  0.5384615384615384\n",
      "i =   650\n",
      "6/6 [==============================] - 0s 80ms/step - loss: 0.5645\n",
      "i =   700\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.6372\n",
      "i =   750\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.6670\n",
      "i =   800\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.6613\n",
      "Evaluate on valid set:  0.5987525987525988\n",
      "This is the best eval res, saving the model...\n",
      "saving model now = 2022-07-25 14:56:15.925498\n",
      "just saved\n",
      "i =   850\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 0.8150\n",
      "i =   900\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.6847\n",
      "i =   950\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.6538\n",
      "i =   1000\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.7547\n",
      "Evaluate on valid set:  0.4594594594594595\n",
      "i =   1050\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.5555\n",
      "i =   1100\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 0.6805\n",
      "i =   1150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.6771\n",
      "i =   1200\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 0.6902\n",
      "Evaluate on valid set:  0.5467775467775468\n",
      "i =   1250\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.7560\n",
      "i =   1300\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.6669\n",
      "i =   1350\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.6790\n",
      "i =   1400\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.5917\n",
      "Evaluate on valid set:  0.5384615384615384\n",
      "i =   1450\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.7355\n",
      "i =   1500\n",
      "11/11 [==============================] - 1s 83ms/step - loss: 0.6162\n",
      "i =   1550\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.6772\n",
      "i =   1600\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.6738\n",
      "Evaluate on valid set:  0.5592515592515592\n",
      "i =   1650\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.7189\n",
      "i =   1700\n",
      "7/7 [==============================] - 1s 79ms/step - loss: 0.9056\n",
      "i =   1750\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.6332\n",
      "i =   1800\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.7683\n",
      "Evaluate on valid set:  0.5467775467775468\n",
      "i =   1850\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.7557\n",
      "i =   1900\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.8077\n",
      "22.98045984109243\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "pNet.train(x_train,y_train,x_test,y_test, epochs=1, saveModel=True, model_name=\"cornell_prepro_characters_1epoch_10proto\")\n",
    "execution_time = (time.time() - start_time) / 60\n",
    "print(execution_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Soon then.',\n",
       "  \"I'll save the last dance for you.\",\n",
       "  \"They're running me ragged.\",\n",
       "  'Nothing but question day and night I love it!',\n",
       "  \"Come to dinner and 1'1 tell you all about it.\",\n",
       "  \"There's a Bajoran band at the officer's mess.\",\n",
       "  \"You can' t imagine them, Jean Luc.\",\n",
       "  \"They're kids!\",\n",
       "  'All with advance degrees in xenobiology and out to conquer every disease in the quadrant.',\n",
       "  'That was another time.',\n",
       "  'But we do have one advantage.',\n",
       "  'He needs your blood to live.',\n",
       "  'He might come after you first.',\n",
       "  \"I can't be sure but the rate of decay seems to be accelerating.\",\n",
       "  'As a result the temporal sequencing was never activated.',\n",
       "  'Remember, he was supposed to replace you at nearly your current age.',\n",
       "  'He was engineered to skip thirty years of life.',\n",
       "  'But since the RNA sequencing was never activated, his cellular structure has started to break down.',\n",
       "  \"He's dying.\",\n",
       "  'The more I studied his DNA the more confusing it got.',\n",
       "  'Finally I could only come to one conclusion Shinzon was created with temporal RNA sequencing.',\n",
       "  'He was designed so that at a certain point his aging process could be accelerated to reach your age more quickly, so he could replace you.',\n",
       "  \"Aside from slightly elevated adrenalin and serotonin levels, you're completely normal.\",\n",
       "  \"Jean Luc, Whatever you were Right now you're the man you've made yourself.\",\n",
       "  \"He's someone else.\",\n",
       "  'Is he very much like you were?',\n",
       "  'He turned out all right.',\n",
       "  'He was a bit proud as I recall.',\n",
       "  \"You're working late.\",\n",
       "  'It has the ability to consume organic material at the subatomic level.',\n",
       "  \"I can't overestimate the danger of Thalaron radiation, Jean Luc.\",\n",
       "  'A microscopic amount could kill every living thing on this ship in a matter of seconds.',\n",
       "  'About twenty-five years ago.',\n",
       "  'They probably used a hair follicle or skin cell.',\n",
       "  'If you start tearing up I promise to beam you out.',\n",
       "  'Level one medical emergency.',\n",
       "  \"There's no crying in Starfleet.\",\n",
       "  \"Sort of like losing a son and gaining an empath, isn't it?\",\n",
       "  \"It'll serve you right.\"],\n",
       " ['We missed you in Church today, Frank.',\n",
       "  \"I'm having dinner with W It's I loved it he No, I was, I was, I was just <u>learning</u> on, it's a You have no right to I really think that <u>business</u> matters should be discussed between you t He's on the Island, he'll be back on I think I should talk to my agent, Marty, you and I should, we should, really not discuss we had a script conference Hi.\",\n",
       "  \"I hope I'm not disturbing I Oh.\",\n",
       "  'Who is that ?',\n",
       "  'But we I like you, too.',\n",
       "  \"I feel so <u>close</u> to you <u>You</u> know Where's your bathroom?\",\n",
       "  'I love Jewish men.',\n",
       "  'Matzoh!',\n",
       "  'Are you Jewish?',\n",
       "  \"I'm not a <u>child</u> I have <u>feelings</u> Don't you don't, don't don't You can't treat me like this.\",\n",
       "  \"I'm not a child!\",\n",
       "  'No, are you kidding me, Bob, not at all.',\n",
       "  \"I'm so comfortable with that, Walt, I can't <u>tell</u> you Bob are you alright ?\",\n",
       "  'Hello.',\n",
       "  \"I'm sorry Walt it's gone beyond that.\",\n",
       "  \"He treated me as if I were a child she has a <u>home</u> she works with <u>animals</u>, she The minute I read that script I said I'm only trying to I What?\",\n",
       "  \"I have a five-o'clock plane to catch.\",\n",
       "  'We, we have to give it.',\n",
       "  'Yes.',\n",
       "  'yes Wally and, and, and did she ?',\n",
       "  'And she did the seven shows I What?',\n",
       "  \"I can't do it, Wally I I they treat me like a <u>child</u>.\",\n",
       "  'I, I to bare my <u>body</u>.',\n",
       "  'Everybody, they, they, they treat me like a Is Is the Movie!',\n",
       "  \"I don't want to take my shirt off in that con What are these things that they're asking of me ?\",\n",
       "  \"Wha wha wha I try to be good; the only thing I care about is It isn't <u>right</u>.\",\n",
       "  'I can\\'t I I know I si I, they, I don\\'t know if they told me it was in the con I can\\'t do it, Walt. \"',\n",
       "  'but still it rises up It rises up, Frank, high as it can go.\"',\n",
       "  \"This scene is why I'm doing the movie.\",\n",
       "  '\"Look at the mill, Frank look at the way it goes around <u>half</u> of the time the darned wheel\\'s under water, but \" How many times in your <u>life</u> do you get a speech like that?',\n",
       "  \"What, what's there to <u>think</u> about?\",\n",
       "  \"The scene's perfect I, I get to say How can I thank you?\",\n",
       "  'How can I repay you for this part?',\n",
       "  \"It's a what a, thank you for this part.\",\n",
       "  \"The first scene at the Old Mill Don't let me dis I'll just I just\"]]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0\n",
      "i =   0\n",
      "2/2 [==============================] - 5s 87ms/step - loss: 0.1829\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-d8ca94c48f2a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpNet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaveModel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cornell_prepro_characters_1epoch_10proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturnValidationAccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mexecution_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexecution_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/protorynet/src/protoryNet/protoryNet.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, x_train, y_train, x_test, y_test, saveModel, returnValidationAccuracy, model_name, epochs)\u001b[0m\n\u001b[1;32m    230\u001b[0m                 \u001b[0;31m#Evaluate after every 200 iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m                     \u001b[0my_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Evaluate on valid set: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m                     \u001b[0mhistory_validation_accuracy_in_epoch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/protorynet/src/protoryNet/protoryNet.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x_valid, y)\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0my_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx_valid\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m             \u001b[0my_preds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_preds\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "pNet.train(x_train,y_train,x_test,y_test, epochs=1, saveModel=True, model_name=\"cornell_prepro_characters_1epoch_10proto\", returnValidationAccuracy = True)\n",
    "execution_time = (time.time() - start_time) / 60\n",
    "print(execution_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model testing (from saved model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[db] model.input =  KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.string, name='input_2'), name='input_2', description=\"created by layer 'input_2'\")\n",
      "[db] protoLayerName =  proto_layer\n",
      "[db] protoLayer =  <protoryNet.ProtoryNet.createModel.<locals>.prototypeLayer object at 0x7fb419327250>\n",
      "[db] protoLayer.output =  (<KerasTensor: shape=(1, None, 10) dtype=float32 (created by layer 'proto_layer')>, <KerasTensor: shape=(10, 512) dtype=float32 (created by layer 'proto_layer')>)\n",
      "[db] distanceLayer.output =  KerasTensor(type_spec=TensorSpec(shape=(1, None, 10), dtype=tf.float32, name=None), name='distance_layer/PartitionedCall:0', description=\"created by layer 'distance_layer'\")\n",
      "Model: \"custom_model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None,)]                 0         \n",
      "                                                                 \n",
      " keras_layer_1 (KerasLayer)  (None, 512)               256797824 \n",
      "                                                                 \n",
      " tf.expand_dims_1 (TFOpLambd  (1, None, 512)           0         \n",
      " a)                                                              \n",
      "                                                                 \n",
      " proto_layer (prototypeLayer  ((1, None, 10),          5120      \n",
      " )                            (10, 512))                         \n",
      "                                                                 \n",
      " distance_layer (distanceLay  (1, None, 10)            0         \n",
      " er)                                                             \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               [(1, None, 128),          71168     \n",
      "                              (1, 128),                          \n",
      "                              (1, 128)]                          \n",
      "                                                                 \n",
      " tf.__operators__.getitem_1   (1, 128)                 0         \n",
      " (SlicingOpLambda)                                               \n",
      "                                                                 \n",
      " dense_1 (Dense)             (1, 1)                    129       \n",
      "                                                                 \n",
      " tf.compat.v1.squeeze_1 (TFO  (1,)                     0         \n",
      " pLambda)                                                        \n",
      "                                                                 \n",
      " model_4 (Functional)        ((1, None, 10),           256802944 \n",
      "                              (10, 512))                         \n",
      "                                                                 \n",
      " model_5 (Functional)        (1, None, 10)             256802944 \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 256,874,241\n",
      "Trainable params: 256,874,241\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_path = 'cornell_prepro_characters_1epoch_10proto' + '.h5'\n",
    "\n",
    "pNet_saved = ProtoryNet()\n",
    "model = pNet_saved.createModel(np.zeros((number_prototypes, 512)), number_prototypes)\n",
    "model.load_weights(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sentences_embedded = pNet_saved.embed(sample_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The evaluation results state that everything should be classified as \"male speaker\", the test accuracy is low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.4835634,\n",
       "  0.48410264,\n",
       "  0.48057833,\n",
       "  0.49563274,\n",
       "  0.4869299,\n",
       "  0.47352034,\n",
       "  0.5124197,\n",
       "  0.48087862,\n",
       "  0.48483503,\n",
       "  0.47263864,\n",
       "  0.4904226,\n",
       "  0.49059698,\n",
       "  0.4920593,\n",
       "  0.4829499,\n",
       "  0.49741504,\n",
       "  0.49083006,\n",
       "  0.48096627,\n",
       "  0.5149506,\n",
       "  0.48934457,\n",
       "  0.4848144,\n",
       "  0.500455,\n",
       "  0.4836769,\n",
       "  0.48949644,\n",
       "  0.49015084,\n",
       "  0.48976552,\n",
       "  0.4954207,\n",
       "  0.50848293,\n",
       "  0.48579854,\n",
       "  0.489393,\n",
       "  0.47969067,\n",
       "  0.49661282,\n",
       "  0.50852746,\n",
       "  0.47646448,\n",
       "  0.48497608,\n",
       "  0.49140352,\n",
       "  0.49369612,\n",
       "  0.5086437,\n",
       "  0.4758523,\n",
       "  0.49391797,\n",
       "  0.48972082,\n",
       "  0.4938262,\n",
       "  0.48292345,\n",
       "  0.49029905,\n",
       "  0.4869105,\n",
       "  0.49913675,\n",
       "  0.47586304,\n",
       "  0.48828253,\n",
       "  0.4774784,\n",
       "  0.48700586,\n",
       "  0.48327342,\n",
       "  0.48628867,\n",
       "  0.4840986,\n",
       "  0.4875245,\n",
       "  0.5060973,\n",
       "  0.5041454,\n",
       "  0.48440757,\n",
       "  0.49492946,\n",
       "  0.4766115,\n",
       "  0.4848245,\n",
       "  0.4867894,\n",
       "  0.4956751,\n",
       "  0.48220205,\n",
       "  0.5126782,\n",
       "  0.47674713,\n",
       "  0.50812817,\n",
       "  0.48352152,\n",
       "  0.49053317,\n",
       "  0.4983942,\n",
       "  0.4880965,\n",
       "  0.49172395,\n",
       "  0.5020753,\n",
       "  0.511954,\n",
       "  0.50016737,\n",
       "  0.4877936,\n",
       "  0.4856325,\n",
       "  0.48270223,\n",
       "  0.4731144,\n",
       "  0.48218316,\n",
       "  0.4801297,\n",
       "  0.47461915,\n",
       "  0.49238676,\n",
       "  0.49579632,\n",
       "  0.4755661,\n",
       "  0.49897304,\n",
       "  0.5074512,\n",
       "  0.48394436,\n",
       "  0.49433327,\n",
       "  0.48252255,\n",
       "  0.48745328,\n",
       "  0.48216775,\n",
       "  0.47812366,\n",
       "  0.48775008,\n",
       "  0.48765823,\n",
       "  0.5096151,\n",
       "  0.47556117,\n",
       "  0.4890038,\n",
       "  0.49460292,\n",
       "  0.48375317,\n",
       "  0.496799,\n",
       "  0.50065035,\n",
       "  0.484592,\n",
       "  0.48281336,\n",
       "  0.4935099,\n",
       "  0.4951707,\n",
       "  0.49464825,\n",
       "  0.49349803,\n",
       "  0.4846038,\n",
       "  0.48615012,\n",
       "  0.4791081,\n",
       "  0.47384623,\n",
       "  0.47468957,\n",
       "  0.49342048,\n",
       "  0.507467,\n",
       "  0.5006235,\n",
       "  0.5133125,\n",
       "  0.49250713,\n",
       "  0.4949777,\n",
       "  0.5153335,\n",
       "  0.50893104,\n",
       "  0.4804986,\n",
       "  0.4929617,\n",
       "  0.4762303,\n",
       "  0.4881407,\n",
       "  0.5015554,\n",
       "  0.5040901,\n",
       "  0.47775742,\n",
       "  0.4923345,\n",
       "  0.5086149,\n",
       "  0.50019836,\n",
       "  0.47823524,\n",
       "  0.49926507,\n",
       "  0.4868186,\n",
       "  0.48390505,\n",
       "  0.48702896,\n",
       "  0.4985111,\n",
       "  0.4832264,\n",
       "  0.4887037,\n",
       "  0.5069113,\n",
       "  0.48049662,\n",
       "  0.48349303,\n",
       "  0.4838589,\n",
       "  0.4926734,\n",
       "  0.48544735,\n",
       "  0.4851154,\n",
       "  0.49468997,\n",
       "  0.47584835,\n",
       "  0.47587875,\n",
       "  0.49098372,\n",
       "  0.49558595,\n",
       "  0.48869523,\n",
       "  0.49632704,\n",
       "  0.4901639,\n",
       "  0.478893,\n",
       "  0.48522508,\n",
       "  0.487872,\n",
       "  0.48173547,\n",
       "  0.5041172,\n",
       "  0.47209638,\n",
       "  0.47848004,\n",
       "  0.47311595,\n",
       "  0.4841175,\n",
       "  0.51502275,\n",
       "  0.49486434,\n",
       "  0.48724622,\n",
       "  0.4899685,\n",
       "  0.50400615,\n",
       "  0.510789,\n",
       "  0.49678358,\n",
       "  0.51244766,\n",
       "  0.47703683,\n",
       "  0.46645552,\n",
       "  0.48481765,\n",
       "  0.47535625,\n",
       "  0.48256668,\n",
       "  0.493067,\n",
       "  0.4977464,\n",
       "  0.4951699,\n",
       "  0.5089456,\n",
       "  0.49002382,\n",
       "  0.48480442,\n",
       "  0.4979156,\n",
       "  0.48723048,\n",
       "  0.48164225,\n",
       "  0.5055822,\n",
       "  0.49002507,\n",
       "  0.49786836,\n",
       "  0.4825968,\n",
       "  0.5030186,\n",
       "  0.51356214,\n",
       "  0.48296013,\n",
       "  0.5082061,\n",
       "  0.499396,\n",
       "  0.5069209,\n",
       "  0.49877718,\n",
       "  0.49347562,\n",
       "  0.47949842,\n",
       "  0.49690235,\n",
       "  0.4973733,\n",
       "  0.5015495,\n",
       "  0.4813078,\n",
       "  0.48395395,\n",
       "  0.48634213,\n",
       "  0.49730986,\n",
       "  0.5024913,\n",
       "  0.4996437,\n",
       "  0.4832025,\n",
       "  0.50417286,\n",
       "  0.48668513,\n",
       "  0.5042331,\n",
       "  0.4885769,\n",
       "  0.5028884,\n",
       "  0.50186974,\n",
       "  0.49661982,\n",
       "  0.4796365,\n",
       "  0.4806279,\n",
       "  0.49475425,\n",
       "  0.47941488,\n",
       "  0.49034324,\n",
       "  0.48861313,\n",
       "  0.4931361,\n",
       "  0.5108853,\n",
       "  0.5116597,\n",
       "  0.48366114,\n",
       "  0.5172914,\n",
       "  0.5001965,\n",
       "  0.50809985,\n",
       "  0.48963916,\n",
       "  0.4940501,\n",
       "  0.49984127,\n",
       "  0.5053549,\n",
       "  0.47451055,\n",
       "  0.48728392,\n",
       "  0.4754485,\n",
       "  0.4823776,\n",
       "  0.5011209,\n",
       "  0.49044818,\n",
       "  0.476514,\n",
       "  0.48781732,\n",
       "  0.4869169,\n",
       "  0.49060374,\n",
       "  0.47178212,\n",
       "  0.49634355,\n",
       "  0.48733667,\n",
       "  0.47583914,\n",
       "  0.48382604,\n",
       "  0.4955372,\n",
       "  0.48851213,\n",
       "  0.48918733,\n",
       "  0.48926136,\n",
       "  0.50100726,\n",
       "  0.4968523,\n",
       "  0.48397875,\n",
       "  0.499347,\n",
       "  0.49063864,\n",
       "  0.49538055,\n",
       "  0.49268636,\n",
       "  0.4811307,\n",
       "  0.5025236,\n",
       "  0.48663735,\n",
       "  0.48540488,\n",
       "  0.4931943,\n",
       "  0.48140737,\n",
       "  0.49552283,\n",
       "  0.47856277,\n",
       "  0.48658067,\n",
       "  0.50253856,\n",
       "  0.50542927,\n",
       "  0.49869782,\n",
       "  0.49463955,\n",
       "  0.4980463,\n",
       "  0.5000475,\n",
       "  0.48672184,\n",
       "  0.4875736,\n",
       "  0.481055,\n",
       "  0.49597877,\n",
       "  0.48535782,\n",
       "  0.4894188,\n",
       "  0.5011053,\n",
       "  0.4858767,\n",
       "  0.49655008,\n",
       "  0.49688864,\n",
       "  0.49775404,\n",
       "  0.47944623,\n",
       "  0.49377185,\n",
       "  0.47652462,\n",
       "  0.48593464,\n",
       "  0.4981436,\n",
       "  0.47218573,\n",
       "  0.48917845,\n",
       "  0.49521786,\n",
       "  0.48979253,\n",
       "  0.5140108,\n",
       "  0.48256952,\n",
       "  0.5022999,\n",
       "  0.49001804,\n",
       "  0.48666874,\n",
       "  0.4965421,\n",
       "  0.49478477,\n",
       "  0.48785442,\n",
       "  0.5057724,\n",
       "  0.4733512,\n",
       "  0.49513283,\n",
       "  0.49239022,\n",
       "  0.48711887,\n",
       "  0.48597145,\n",
       "  0.49779284,\n",
       "  0.4904163,\n",
       "  0.49825433,\n",
       "  0.49098152,\n",
       "  0.50944924,\n",
       "  0.4811095,\n",
       "  0.5079393,\n",
       "  0.4953727,\n",
       "  0.48967943,\n",
       "  0.47500628,\n",
       "  0.47675928,\n",
       "  0.4887033,\n",
       "  0.4868313,\n",
       "  0.4820403,\n",
       "  0.483054,\n",
       "  0.49049595,\n",
       "  0.4891175,\n",
       "  0.47647655,\n",
       "  0.49310246,\n",
       "  0.49702588,\n",
       "  0.4852427,\n",
       "  0.4944961,\n",
       "  0.4790942,\n",
       "  0.49094808,\n",
       "  0.4886873,\n",
       "  0.48772395,\n",
       "  0.49114078,\n",
       "  0.49307165,\n",
       "  0.5067319,\n",
       "  0.47196,\n",
       "  0.4995573,\n",
       "  0.494823,\n",
       "  0.48437122,\n",
       "  0.48300064,\n",
       "  0.47484452,\n",
       "  0.47580987,\n",
       "  0.48261115,\n",
       "  0.49299613,\n",
       "  0.49653998,\n",
       "  0.48699582,\n",
       "  0.48777533,\n",
       "  0.48460817,\n",
       "  0.5149175,\n",
       "  0.50091475,\n",
       "  0.5077261,\n",
       "  0.5031235,\n",
       "  0.50506985,\n",
       "  0.48451725,\n",
       "  0.49826452,\n",
       "  0.49413815,\n",
       "  0.48084497,\n",
       "  0.48417428,\n",
       "  0.48362282,\n",
       "  0.48535377,\n",
       "  0.4784228,\n",
       "  0.47792867,\n",
       "  0.48947775,\n",
       "  0.4798721,\n",
       "  0.4962864,\n",
       "  0.4904617,\n",
       "  0.4831936,\n",
       "  0.49952385,\n",
       "  0.49906126,\n",
       "  0.48540905,\n",
       "  0.4840431,\n",
       "  0.49516243,\n",
       "  0.5016502,\n",
       "  0.51612633,\n",
       "  0.48347586,\n",
       "  0.5011094,\n",
       "  0.47878882,\n",
       "  0.49103856,\n",
       "  0.47721595,\n",
       "  0.4864949,\n",
       "  0.48104846,\n",
       "  0.4972406,\n",
       "  0.48362783,\n",
       "  0.51881665,\n",
       "  0.50547993,\n",
       "  0.4925946,\n",
       "  0.4832634,\n",
       "  0.4956658,\n",
       "  0.504181,\n",
       "  0.49889192,\n",
       "  0.48079643,\n",
       "  0.4906095,\n",
       "  0.49654105,\n",
       "  0.4887809,\n",
       "  0.48680505,\n",
       "  0.51673996,\n",
       "  0.50026083,\n",
       "  0.48021477,\n",
       "  0.4939272,\n",
       "  0.4999416,\n",
       "  0.4958873,\n",
       "  0.47991735,\n",
       "  0.47933906,\n",
       "  0.49629426,\n",
       "  0.4960427,\n",
       "  0.49093786,\n",
       "  0.4924529,\n",
       "  0.4905171,\n",
       "  0.48713303,\n",
       "  0.49398366,\n",
       "  0.4815526,\n",
       "  0.48280948,\n",
       "  0.48103645,\n",
       "  0.4986141,\n",
       "  0.4982683,\n",
       "  0.49518067,\n",
       "  0.4668402,\n",
       "  0.48323134,\n",
       "  0.480609,\n",
       "  0.48110372,\n",
       "  0.4894532,\n",
       "  0.49335316,\n",
       "  0.5121191,\n",
       "  0.4769128,\n",
       "  0.48986682,\n",
       "  0.504659,\n",
       "  0.49609622,\n",
       "  0.5085759,\n",
       "  0.48939648,\n",
       "  0.49678922,\n",
       "  0.4919721,\n",
       "  0.4910369,\n",
       "  0.4851553,\n",
       "  0.48271957,\n",
       "  0.4937138,\n",
       "  0.5013141,\n",
       "  0.49424133,\n",
       "  0.49007335,\n",
       "  0.52183056,\n",
       "  0.47601384,\n",
       "  0.48035887,\n",
       "  0.48586833,\n",
       "  0.47626787,\n",
       "  0.50243396,\n",
       "  0.48740503,\n",
       "  0.49641517,\n",
       "  0.4806181,\n",
       "  0.49145097,\n",
       "  0.4789056,\n",
       "  0.49610326,\n",
       "  0.4717371,\n",
       "  0.49736986,\n",
       "  0.4920194,\n",
       "  0.5012013,\n",
       "  0.49277526,\n",
       "  0.49818203,\n",
       "  0.485099,\n",
       "  0.49727654,\n",
       "  0.48690525,\n",
       "  0.5031055,\n",
       "  0.4840891,\n",
       "  0.49494207,\n",
       "  0.50488955,\n",
       "  0.49164695,\n",
       "  0.49105418,\n",
       "  0.49761248,\n",
       "  0.4904967,\n",
       "  0.48228472,\n",
       "  0.49584985,\n",
       "  0.48719573,\n",
       "  0.48105597,\n",
       "  0.4921132,\n",
       "  0.5014921,\n",
       "  0.48221865,\n",
       "  0.5114437,\n",
       "  0.49014005,\n",
       "  0.48057204,\n",
       "  0.496689,\n",
       "  0.49905717,\n",
       "  0.50918764,\n",
       "  0.51395816,\n",
       "  0.51491284],\n",
       " 0.5987525987525988)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pNet_saved.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the prototypes changed from the originals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Please will you believe me.',\n",
       " 1: \"Let them stay 'til morning.\",\n",
       " 2: \"So, how'd a shrink ever get to be a priest?\",\n",
       " 3: \"You can't ask me that!\",\n",
       " 4: \"Hi, I'm Steven.\",\n",
       " 5: 'You definitely do.',\n",
       " 6: 'On your piano, that is the swap.',\n",
       " 7: 'Books.',\n",
       " 8: 'Hello, Gabriel.',\n",
       " 9: 'Is this like your old convent?'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prototypes = pNet_saved.showPrototypes(sample_sentences, sample_sentences_embedded, number_prototypes, printOutput=False, return_prototypes = True)\n",
    "prototypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['My loyalty was never to my country.', 'Because it is my duty.', 'Yes, Mr. President.', \"That's affirmative.\", 'Roger.', 'Air Force One, acknowledged.', 'tNT.', 'EMERGENCY PARACHUTE LAUNCH RAMP.', 'About goddamn time.', 'Over the Black Sea.', 'I can probably get us to Turkey or Georgia.', 'Not even close.', \"Hell, we can't even make Syria or Iraq.\", \"We've stopped dumping but we've only got about twenty minutes of fuel left.\", 'Avionics compartment!', \"It's the only place.\", \"You better get Zedeck down there fast Unless, of course, you'd rather be a martyr than a savior.\", 'Well it worked.', 'why did they do that?', 'We checked the manifest.', 'Everyone was accounted for.', 'Nine.', 'Dead.', 'Sir, this plane carries the President of the United States.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.48410264], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testS = x_test[1]\n",
    "print(testS)\n",
    "pNet_saved.predict(testS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"You can't ask me that!\",\n",
       " \"You can't ask me that!\",\n",
       " \"Hi, I'm Steven.\",\n",
       " 'You definitely do.',\n",
       " 'Hello, Gabriel.',\n",
       " 'Books.',\n",
       " 'Books.',\n",
       " 'Books.',\n",
       " 'Hello, Gabriel.',\n",
       " 'Books.',\n",
       " \"Let them stay 'til morning.\",\n",
       " \"You can't ask me that!\",\n",
       " \"Let them stay 'til morning.\",\n",
       " \"Let them stay 'til morning.\",\n",
       " 'Books.',\n",
       " \"You can't ask me that!\",\n",
       " \"So, how'd a shrink ever get to be a priest?\",\n",
       " 'You definitely do.',\n",
       " \"You can't ask me that!\",\n",
       " 'On your piano, that is the swap.',\n",
       " 'You definitely do.',\n",
       " 'Books.',\n",
       " 'Books.',\n",
       " 'On your piano, that is the swap.']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trajectory = pNet_saved.showTrajectory(testS, sample_sentences, sample_sentences_embedded)\n",
    "trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_trajectory(list_of_sentences):\n",
    "    '''\n",
    "    given a list of sentences (usually a list of prototypes), it returns the prediction for each of them\n",
    "    '''\n",
    "    pred = []\n",
    "    for prot in list_of_sentences:\n",
    "        pred.append(pNet_saved.predict([prot])[0])\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5000223,\n",
       " 0.5024166,\n",
       " 0.50159353,\n",
       " 0.5137318,\n",
       " 0.50853634,\n",
       " 0.49461144,\n",
       " 0.5110517,\n",
       " 0.50164145,\n",
       " 0.5008188,\n",
       " 0.5145239]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_trajectory(prototypes.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5137318,\n",
       " 0.5137318,\n",
       " 0.50853634,\n",
       " 0.49461144,\n",
       " 0.5008188,\n",
       " 0.50164145,\n",
       " 0.50164145,\n",
       " 0.50164145,\n",
       " 0.5008188,\n",
       " 0.50164145,\n",
       " 0.5024166,\n",
       " 0.5137318,\n",
       " 0.5024166,\n",
       " 0.5024166,\n",
       " 0.50164145,\n",
       " 0.5137318,\n",
       " 0.50159353,\n",
       " 0.49461144,\n",
       " 0.5137318,\n",
       " 0.5110517,\n",
       " 0.49461144,\n",
       " 0.50164145,\n",
       " 0.50164145,\n",
       " 0.5110517]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_trajectory(trajectory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimation of training time using leave-one-group-out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.3425393065920574"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of days to train models using leave-one-group-out\n",
    "groups = 10\n",
    "epochs = 20\n",
    "execution_time * epochs * groups / 60 / 24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "cornell_prepro_characters = pd.read_csv('datasets/cornell_corpus/cornell_prepro_characters.csv')\n",
    "\n",
    "# Split data\n",
    "X = cornell_prepro_characters['text_with_punctuation']\n",
    "y = np.array(cornell_prepro_characters['gender'] == 'F').astype(int)\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = myfunctions.balanced_split_train_val_test(X, y, train_split = 0.7, val_split = 0.2, test_split = 0.1, random_seed = 32)\n",
    "\n",
    "# Saving to pickle format\n",
    "directory =  'datasets/cornell_corpus/cornell_prepro_characters_70train_20val_10test/'\n",
    "\n",
    "with open(directory +'x_train', 'wb') as f:\n",
    "     pickle.dump(X_train, f)\n",
    "with open(directory +'x_val', 'wb') as f:\n",
    "     pickle.dump(X_val, f)\n",
    "with open(directory +'x_test', 'wb') as f:\n",
    "     pickle.dump(X_test, f)\n",
    "\n",
    "with open(directory +'y_train', 'wb') as f:\n",
    "     pickle.dump(y_train, f)\n",
    "with open(directory +'y_val', 'wb') as f:\n",
    "     pickle.dump(y_val, f)\n",
    "with open(directory +'y_test', 'wb') as f:\n",
    "     pickle.dump(y_test, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /nfshome/students/cm007951/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "Traceback (most recent call last):\n",
      "  File \"code/train_protorynet.py\", line 52, in <module>\n",
      "    sample_size_sentences = arg.sample_size_sentences\n",
      "NameError: name 'arg' is not defined\n"
     ]
    }
   ],
   "source": [
    "!python code/train_protorynet.py --dataset_path=datasets/cornell_corpus/cornell_prepro_characters_70train_20val_10test/ --results_path=results/protorynet_models/ --results_prefix=cornell_prepro_characters_70train_20val_10test --epochs=2 --number_prototypes=10 --type_init=random --sample_size_sentences=20000 --init_prototypes_seed=16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ProtoryNet_example.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
