{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observations about prototype initializations\n",
    "\n",
    "In it's original version, ProtoryNet uses kmedois to initialize its prototypes. \n",
    "More specifically, if we use $k$ prototypes in the model, k-medoids clustering is applied on some sentences of the training set with $\\text{number of clusters} = k.$\n",
    "The resulting $k$ centroids are used as the initial prototypes. \n",
    "Note that note all sentences in the training are used in the clustering because with after more than 30000 sentences, approximately, the kmedoids algorithm runs into memory issues. \n",
    "\n",
    "In this notebook we illustrate that when using the kmedoids initialization in our dataset some prototypes are redundant.\n",
    "In other words, some of the initial prototypes are repeated, they are the same sentence.\n",
    "In previous experiments we observed that prototypes sometimes get \"stucked\" (the don't change) and lack diversity.\n",
    "These two problems could be feeding one another.\n",
    "The lack of diversity persist after training for many epochs, which might indicate that when starting with repeated prototypes it's hard for the model to adquire prototype heterogenity.  \n",
    " \n",
    "We propose, as an alternative, to use a random initialization of the prototypes. \n",
    "This comes with the possibility of starting with a \"bad random selection\" of prototypes that won't let the model learn properly.\n",
    "As with other algorithms that can be affected by the initialization, we can run the model several times and see how the accuracy measures behave. \n",
    "\n",
    "We leave a study on the impact of different initialization for the future.  \n",
    "For the moment we focus on warranting diversity in the initialization of the prototypes. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 36,
     "status": "ok",
     "timestamp": 1642361175331,
     "user": {
      "displayName": "Mariana Chaves",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GitK6a8J23ZNS4lannJlrPyUTG-wmSWzMTrridp7OI=s64",
      "userId": "14956690162580527944"
     },
     "user_tz": -60
    },
    "id": "KGU7rAmNfmjF"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /nfshome/students/cm007951/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /nfshome/students/cm007951/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import argparse\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "import myfunctions\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "sys.path.append('../src/protoryNet/')\n",
    "from protoryNet import ProtoryNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/nfshome/students/cm007951/text-models\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6IkGwcJaN4f_"
   },
   "source": [
    "# Import datasets and data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>characterID</th>\n",
       "      <th>movieID</th>\n",
       "      <th>character_name</th>\n",
       "      <th>gender</th>\n",
       "      <th>movie_title</th>\n",
       "      <th>movie_year</th>\n",
       "      <th>movieGroup</th>\n",
       "      <th>text_with_punctuation</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>F</td>\n",
       "      <td>10 things i hate about you</td>\n",
       "      <td>1999</td>\n",
       "      <td>1</td>\n",
       "      <td>They do not! I hope so. Let's go. Okay you're ...</td>\n",
       "      <td>They do not I hope so Lets go Okay youre gonna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>u100</td>\n",
       "      <td>m6</td>\n",
       "      <td>AMY</td>\n",
       "      <td>F</td>\n",
       "      <td>8mm</td>\n",
       "      <td>1999</td>\n",
       "      <td>1</td>\n",
       "      <td>She died in her sleep three days ago. It was i...</td>\n",
       "      <td>She died in her sleep three days ago It was in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>u1001</td>\n",
       "      <td>m65</td>\n",
       "      <td>PETE</td>\n",
       "      <td>M</td>\n",
       "      <td>from dusk till dawn</td>\n",
       "      <td>1996</td>\n",
       "      <td>5</td>\n",
       "      <td>Six-fifty. Knock yourself out. That's all that...</td>\n",
       "      <td>Sixfifty Knock yourself out Thats all thats be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>u1007</td>\n",
       "      <td>m66</td>\n",
       "      <td>BLONDELL</td>\n",
       "      <td>F</td>\n",
       "      <td>g.i. jane</td>\n",
       "      <td>1997</td>\n",
       "      <td>1</td>\n",
       "      <td>Wow Uh don't see it. There's no signature. But...</td>\n",
       "      <td>Wow Uh dont see it Theres no signature But han...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>u1008</td>\n",
       "      <td>m66</td>\n",
       "      <td>C.O.</td>\n",
       "      <td>M</td>\n",
       "      <td>g.i. jane</td>\n",
       "      <td>1997</td>\n",
       "      <td>1</td>\n",
       "      <td>Of course, but there's more Uh, V.I.P. securit...</td>\n",
       "      <td>Of course but theres more Uh VIP security arra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2399</th>\n",
       "      <td>2399</td>\n",
       "      <td>u983</td>\n",
       "      <td>m64</td>\n",
       "      <td>ALICE</td>\n",
       "      <td>F</td>\n",
       "      <td>friday the 13th</td>\n",
       "      <td>2009</td>\n",
       "      <td>3</td>\n",
       "      <td>Maybe we should wait for Mr. Christy. The kill...</td>\n",
       "      <td>Maybe we should wait for Mr Christy The killer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2400</th>\n",
       "      <td>2400</td>\n",
       "      <td>u985</td>\n",
       "      <td>m64</td>\n",
       "      <td>BILL</td>\n",
       "      <td>M</td>\n",
       "      <td>friday the 13th</td>\n",
       "      <td>2009</td>\n",
       "      <td>3</td>\n",
       "      <td>It's over twenty miles to the crossroads. Stev...</td>\n",
       "      <td>Its over twenty miles to the crossroads Stevel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2401</th>\n",
       "      <td>2401</td>\n",
       "      <td>u989</td>\n",
       "      <td>m64</td>\n",
       "      <td>MARCIE</td>\n",
       "      <td>F</td>\n",
       "      <td>friday the 13th</td>\n",
       "      <td>2009</td>\n",
       "      <td>3</td>\n",
       "      <td>Gotta pee. You're lying on my bladder. Like wa...</td>\n",
       "      <td>Gotta pee Youre lying on my bladder Like waves...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2402</th>\n",
       "      <td>2402</td>\n",
       "      <td>u993</td>\n",
       "      <td>m64</td>\n",
       "      <td>STEVE</td>\n",
       "      <td>M</td>\n",
       "      <td>friday the 13th</td>\n",
       "      <td>2009</td>\n",
       "      <td>3</td>\n",
       "      <td>I've got to go to town and pick up the trailer...</td>\n",
       "      <td>Ive got to go to town and pick up the trailer ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2403</th>\n",
       "      <td>2403</td>\n",
       "      <td>u998</td>\n",
       "      <td>m65</td>\n",
       "      <td>KATE</td>\n",
       "      <td>F</td>\n",
       "      <td>from dusk till dawn</td>\n",
       "      <td>1996</td>\n",
       "      <td>5</td>\n",
       "      <td>Everybody goes home! I'm going for 'em! I swea...</td>\n",
       "      <td>Everybody goes home Im going for em I swear to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2404 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0 characterID movieID character_name gender  \\\n",
       "0              0          u0      m0         BIANCA      F   \n",
       "1              1        u100      m6            AMY      F   \n",
       "2              2       u1001     m65           PETE      M   \n",
       "3              3       u1007     m66       BLONDELL      F   \n",
       "4              4       u1008     m66           C.O.      M   \n",
       "...          ...         ...     ...            ...    ...   \n",
       "2399        2399        u983     m64          ALICE      F   \n",
       "2400        2400        u985     m64           BILL      M   \n",
       "2401        2401        u989     m64         MARCIE      F   \n",
       "2402        2402        u993     m64          STEVE      M   \n",
       "2403        2403        u998     m65           KATE      F   \n",
       "\n",
       "                     movie_title movie_year  movieGroup  \\\n",
       "0     10 things i hate about you       1999           1   \n",
       "1                            8mm       1999           1   \n",
       "2            from dusk till dawn       1996           5   \n",
       "3                      g.i. jane       1997           1   \n",
       "4                      g.i. jane       1997           1   \n",
       "...                          ...        ...         ...   \n",
       "2399             friday the 13th       2009           3   \n",
       "2400             friday the 13th       2009           3   \n",
       "2401             friday the 13th       2009           3   \n",
       "2402             friday the 13th       2009           3   \n",
       "2403         from dusk till dawn       1996           5   \n",
       "\n",
       "                                  text_with_punctuation  \\\n",
       "0     They do not! I hope so. Let's go. Okay you're ...   \n",
       "1     She died in her sleep three days ago. It was i...   \n",
       "2     Six-fifty. Knock yourself out. That's all that...   \n",
       "3     Wow Uh don't see it. There's no signature. But...   \n",
       "4     Of course, but there's more Uh, V.I.P. securit...   \n",
       "...                                                 ...   \n",
       "2399  Maybe we should wait for Mr. Christy. The kill...   \n",
       "2400  It's over twenty miles to the crossroads. Stev...   \n",
       "2401  Gotta pee. You're lying on my bladder. Like wa...   \n",
       "2402  I've got to go to town and pick up the trailer...   \n",
       "2403  Everybody goes home! I'm going for 'em! I swea...   \n",
       "\n",
       "                                                   text  \n",
       "0     They do not I hope so Lets go Okay youre gonna...  \n",
       "1     She died in her sleep three days ago It was in...  \n",
       "2     Sixfifty Knock yourself out Thats all thats be...  \n",
       "3     Wow Uh dont see it Theres no signature But han...  \n",
       "4     Of course but theres more Uh VIP security arra...  \n",
       "...                                                 ...  \n",
       "2399  Maybe we should wait for Mr Christy The killer...  \n",
       "2400  Its over twenty miles to the crossroads Stevel...  \n",
       "2401  Gotta pee Youre lying on my bladder Like waves...  \n",
       "2402  Ive got to go to town and pick up the trailer ...  \n",
       "2403  Everybody goes home Im going for em I swear to...  \n",
       "\n",
       "[2404 rows x 10 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cornell_prepro_characters = pd.read_csv('datasets/cornell_corpus/cornell_prepro_characters.csv')\n",
    "cornell_prepro_characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X = cornell_prepro_characters['text_with_punctuation']\n",
    "y = np.array(cornell_prepro_characters['gender'] == 'F').astype(int)\n",
    "\n",
    "x_train, x_val, x_test, y_train, y_val, y_test = myfunctions.balanced_split_train_val_test(X, y, train_split = 0.7, val_split = 0.2, test_split = 0.1, random_seed = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving to pickle format\n",
    "# The models will use the datasets we save here\n",
    "directory =  'datasets/cornell_corpus/cornell_prepro_characters_70train_20val_10test/'\n",
    "\n",
    "with open(directory +'x_train', 'wb') as f:\n",
    "     pickle.dump(x_train, f)\n",
    "with open(directory +'x_val', 'wb') as f:\n",
    "     pickle.dump(x_val, f)\n",
    "with open(directory +'x_test', 'wb') as f:\n",
    "     pickle.dump(x_test, f)\n",
    "\n",
    "with open(directory +'y_train', 'wb') as f:\n",
    "     pickle.dump(y_train, f)\n",
    "with open(directory +'y_val', 'wb') as f:\n",
    "     pickle.dump(y_val, f)\n",
    "with open(directory +'y_test', 'wb') as f:\n",
    "     pickle.dump(y_test, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing to use protorynet model's results\n",
    "\n",
    "# In this section there is no need to use the validation set, since we want to evaluate the predictions and accuracy in the test set.\n",
    "# The train set is necessary because we need to map the prototypes (which belong to the train set only)\n",
    "\n",
    "# Guarantee target variable is integer\n",
    "y_train = [int(y) for y in y_train]\n",
    "y_test = [int(y) for y in y_test]\n",
    "\n",
    "# Split text into lists of sentences \n",
    "x_train = myfunctions.split_sentences(x_train)\n",
    "x_test = myfunctions.split_sentences(x_test)\n",
    "\n",
    "# Make a list of sentences (only for training set)\n",
    "train_sentences = []\n",
    "for p in x_train:\n",
    "    train_sentences.extend(p)\n",
    "\n",
    "# We remove very short or very long sentences since they behave as outliers.\n",
    "train_sentences = [i for i in train_sentences if len(i)>5 and len(i)<100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model using kmedoids initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /nfshome/students/cm007951/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "2022-07-28 14:53:19.121868: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-28 14:53:19.130403: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-28 14:53:19.131935: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-28 14:53:19.132911: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-28 14:53:19.133141: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-28 14:53:19.133920: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-28 14:53:19.134689: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-28 14:53:19.922500: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-28 14:53:19.923605: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-28 14:53:19.924522: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-28 14:53:19.925305: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21418 MB memory:  -> device: 0, name: GRID RTX6000-24C, pci bus id: 0000:02:04.0, compute capability: 7.5\n",
      "[db] model.input =  KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.string, name='input_1'), name='input_1', description=\"created by layer 'input_1'\")\n",
      "[db] protoLayerName =  proto_layer\n",
      "[db] protoLayer =  <protoryNet.ProtoryNet.createModel.<locals>.prototypeLayer object at 0x7f28057ddb90>\n",
      "[db] protoLayer.output =  (<KerasTensor: shape=(1, None, 10) dtype=float32 (created by layer 'proto_layer')>, <KerasTensor: shape=(10, 512) dtype=float32 (created by layer 'proto_layer')>)\n",
      "[db] distanceLayer.output =  KerasTensor(type_spec=TensorSpec(shape=(1, None, 10), dtype=tf.float32, name=None), name='distance_layer/PartitionedCall:0', description=\"created by layer 'distance_layer'\")\n",
      "Model: \"custom_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None,)]                 0         \n",
      "                                                                 \n",
      " keras_layer (KerasLayer)    (None, 512)               256797824 \n",
      "                                                                 \n",
      " tf.expand_dims (TFOpLambda)  (1, None, 512)           0         \n",
      "                                                                 \n",
      " proto_layer (prototypeLayer  ((1, None, 10),          5120      \n",
      " )                            (10, 512))                         \n",
      "                                                                 \n",
      " distance_layer (distanceLay  (1, None, 10)            0         \n",
      " er)                                                             \n",
      "                                                                 \n",
      " lstm (LSTM)                 [(1, None, 128),          71168     \n",
      "                              (1, 128),                          \n",
      "                              (1, 128)]                          \n",
      "                                                                 \n",
      " tf.__operators__.getitem (S  (1, 128)                 0         \n",
      " licingOpLambda)                                                 \n",
      "                                                                 \n",
      " dense (Dense)               (1, 1)                    129       \n",
      "                                                                 \n",
      " tf.compat.v1.squeeze (TFOpL  (1,)                     0         \n",
      " ambda)                                                          \n",
      "                                                                 \n",
      " model (Functional)          ((1, None, 10),           256802944 \n",
      "                              (10, 512))                         \n",
      "                                                                 \n",
      " model_1 (Functional)        (1, None, 10)             256802944 \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 256,874,241\n",
      "Trainable params: 256,874,241\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Initial prototypes execution time: 3.8183219909667967\n",
      "Epoch  0\n",
      "i =   0\n",
      "2022-07-28 14:57:53.069259: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8201\n",
      "5/5 [==============================] - 12s 78ms/step - loss: 0.9031\n",
      "Evaluate on valid set:  0.501039501039501\n",
      "This is the best eval res, saving the model...\n",
      "saving model now = 2022-07-28 14:58:39.820543\n",
      "just saved\n",
      "i =   50\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.5595\n",
      "i =   100\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.5853\n",
      "i =   150\n",
      "5/5 [==============================] - 0s 81ms/step - loss: 0.8266\n",
      "i =   200\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.5444\n",
      "Evaluate on valid set:  0.501039501039501\n",
      "i =   250\n",
      "9/9 [==============================] - 1s 80ms/step - loss: 0.5819\n",
      "i =   300\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 0.8289\n",
      "i =   350\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.7493\n",
      "i =   400\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.8017\n",
      "Evaluate on valid set:  0.501039501039501\n",
      "i =   450\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 0.8341\n",
      "i =   500\n",
      "5/5 [==============================] - 0s 78ms/step - loss: 0.9041\n",
      "i =   550\n",
      "6/6 [==============================] - 0s 79ms/step - loss: 0.6212\n",
      "i =   600\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.5735\n",
      "Evaluate on valid set:  0.501039501039501\n",
      "i =   650\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.5725\n",
      "i =   700\n",
      "6/6 [==============================] - 0s 78ms/step - loss: 0.5441\n",
      "i =   750\n",
      "14/14 [==============================] - 1s 80ms/step - loss: 0.5617\n",
      "i =   800\n",
      "9/9 [==============================] - 1s 80ms/step - loss: 0.6074\n",
      "Evaluate on valid set:  0.501039501039501\n",
      "i =   850\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.6091\n",
      "i =   900\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.7856\n",
      "i =   950\n",
      "7/7 [==============================] - 1s 78ms/step - loss: 0.6025\n",
      "i =   1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.7560\n",
      "Evaluate on valid set:  0.501039501039501\n",
      "i =   1050\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.6690\n",
      "i =   1100\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.6444\n",
      "i =   1150\n",
      "5/5 [==============================] - 0s 80ms/step - loss: 0.5899\n",
      "i =   1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 1s 78ms/step - loss: 0.5854\n",
      "Evaluate on valid set:  0.501039501039501\n",
      "i =   1250\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.9297\n",
      "i =   1300\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.8809\n",
      "i =   1350\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 0.5312\n",
      "i =   1400\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.8576\n",
      "Evaluate on valid set:  0.501039501039501\n",
      "i =   1450\n",
      "9/9 [==============================] - 1s 79ms/step - loss: 0.4879\n",
      "i =   1500\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.5616\n",
      "i =   1550\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.6374\n",
      "i =   1600\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.6762\n",
      "Evaluate on valid set:  0.5031185031185031\n",
      "This is the best eval res, saving the model...\n",
      "saving model now = 2022-07-28 15:16:20.019727\n",
      "just saved\n",
      "i =   1650\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.7143\n",
      "Epoch  1\n",
      "i =   0\n",
      "5/5 [==============================] - 0s 78ms/step - loss: 0.8851\n",
      "Evaluate on valid set:  0.501039501039501\n",
      "i =   50\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.6035\n",
      "i =   100\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.6245\n",
      "i =   150\n",
      "5/5 [==============================] - 0s 78ms/step - loss: 0.7876\n",
      "i =   200\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.5533\n",
      "Evaluate on valid set:  0.501039501039501\n",
      "i =   250\n",
      "9/9 [==============================] - 1s 78ms/step - loss: 0.5915\n",
      "i =   300\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 0.7980\n",
      "i =   350\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.7575\n",
      "i =   400\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.7758\n",
      "Evaluate on valid set:  0.501039501039501\n",
      "i =   450\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 0.8048\n",
      "i =   500\n",
      "5/5 [==============================] - 0s 79ms/step - loss: 0.8162\n",
      "i =   550\n",
      "6/6 [==============================] - 0s 78ms/step - loss: 0.6362\n",
      "i =   600\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.6347\n",
      "Evaluate on valid set:  0.501039501039501\n",
      "i =   650\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.5858\n",
      "i =   700\n",
      "6/6 [==============================] - 0s 78ms/step - loss: 0.5797\n",
      "i =   750\n",
      "14/14 [==============================] - 1s 79ms/step - loss: 0.5890\n",
      "i =   800\n",
      "9/9 [==============================] - 1s 77ms/step - loss: 0.6120\n",
      "Evaluate on valid set:  0.501039501039501\n",
      "i =   850\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.6324\n",
      "i =   900\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.8043\n",
      "i =   950\n",
      "7/7 [==============================] - 1s 79ms/step - loss: 0.6094\n",
      "i =   1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.7674\n",
      "Evaluate on valid set:  0.5114345114345115\n",
      "This is the best eval res, saving the model...\n",
      "saving model now = 2022-07-28 15:28:39.069133\n",
      "just saved\n",
      "i =   1050\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.7435\n",
      "i =   1100\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.6072\n",
      "i =   1150\n",
      "5/5 [==============================] - 0s 77ms/step - loss: 0.5980\n",
      "i =   1200\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 0.6009\n",
      "Evaluate on valid set:  0.501039501039501\n",
      "i =   1250\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.8422\n",
      "i =   1300\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.8662\n",
      "i =   1350\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 0.5644\n",
      "i =   1400\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.8749\n",
      "Evaluate on valid set:  0.501039501039501\n",
      "i =   1450\n",
      "9/9 [==============================] - 1s 79ms/step - loss: 0.5443\n",
      "i =   1500\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.5502\n",
      "i =   1550\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.5952\n",
      "i =   1600\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.6228\n",
      "Evaluate on valid set:  0.5031185031185031\n",
      "i =   1650\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.7617\n",
      "{'train_time': 38.86116514205933, 'history_validation_accuracy': [0.5031185031185031, 0.5114345114345115], 'best_validation_accuracy': 0.5114345114345115, 'initial_prototypes': {0: 'Oh, God!', 1: \"I couldn't believe it he just left!\", 2: 'Oh God.', 3: 'Aw, come on.', 4: 'You come up with that yourself?', 5: 'Oh, come on.', 6: 'Oh my God!', 7: 'Oh dear.', 8: 'Oh, dear.', 9: 'Oh no.'}, 'args': Namespace(dataset_path='datasets/cornell_corpus/cornell_prepro_characters_70train_20val_10test/', epochs=2, init_prototypes_seed=16, number_prototypes=10, results_path='results/protorynet_models/', results_prefix='cornell_prepro_characters_70train_20val_10test', sample_size_sentences=20000, type_init='kmedoids')}\n"
     ]
    }
   ],
   "source": [
    "# !python scripts_and_notebooks/train_protorynet.py --dataset_path=datasets/cornell_corpus/cornell_prepro_characters_70train_20val_10test/ --results_path=results/protorynet_models/ --results_prefix=cornell_prepro_characters_70train_20val_10test --epochs=2 --number_prototypes=10 --type_init=kmedoids --sample_size_sentences=20000 --init_prototypes_seed=16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model results\n",
    "\n",
    "The train process, besides saving the model weights, it saves a pickle file with some model information. Among them we can see the initial prototypes chosen by kmedoids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path = 'results/protorynet_models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load results from the model\n",
    "model_name = 'cornell_prepro_characters_70train_20val_10test__2epochs__10prototypes__kmedoidstype_init__20000sample_size_sentences__16init_prototypes_seed'\n",
    "model_kmedoids_results = pickle.load(open(results_path + model_name + '.pickle', 'rb'))\n",
    "\n",
    "# Extract number of prototypes\n",
    "number_prototypes = model_kmedoids_results['args'].number_prototypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that using kmedoids the initial prototypes produce repetitions. \n",
    "Later in the training the prototypes \"don't move\", they get stucked and this might be due to the poor initialization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Oh, God!',\n",
       " 1: \"I couldn't believe it he just left!\",\n",
       " 2: 'Oh God.',\n",
       " 3: 'Aw, come on.',\n",
       " 4: 'You come up with that yourself?',\n",
       " 5: 'Oh, come on.',\n",
       " 6: 'Oh my God!',\n",
       " 7: 'Oh dear.',\n",
       " 8: 'Oh, dear.',\n",
       " 9: 'Oh no.'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_kmedoids_results['initial_prototypes']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we load the model to observe the prototypes after a couple of epochs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[db] model.input =  KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.string, name='input_1'), name='input_1', description=\"created by layer 'input_1'\")\n",
      "[db] protoLayerName =  proto_layer\n",
      "[db] protoLayer =  <protoryNet.ProtoryNet.createModel.<locals>.prototypeLayer object at 0x7feb28706f50>\n",
      "[db] protoLayer.output =  (<KerasTensor: shape=(1, None, 10) dtype=float32 (created by layer 'proto_layer')>, <KerasTensor: shape=(10, 512) dtype=float32 (created by layer 'proto_layer')>)\n",
      "[db] distanceLayer.output =  KerasTensor(type_spec=TensorSpec(shape=(1, None, 10), dtype=tf.float32, name=None), name='distance_layer/PartitionedCall:0', description=\"created by layer 'distance_layer'\")\n",
      "Model: \"custom_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None,)]                 0         \n",
      "                                                                 \n",
      " keras_layer (KerasLayer)    (None, 512)               256797824 \n",
      "                                                                 \n",
      " tf.expand_dims (TFOpLambda)  (1, None, 512)           0         \n",
      "                                                                 \n",
      " proto_layer (prototypeLayer  ((1, None, 10),          5120      \n",
      " )                            (10, 512))                         \n",
      "                                                                 \n",
      " distance_layer (distanceLay  (1, None, 10)            0         \n",
      " er)                                                             \n",
      "                                                                 \n",
      " lstm (LSTM)                 [(1, None, 128),          71168     \n",
      "                              (1, 128),                          \n",
      "                              (1, 128)]                          \n",
      "                                                                 \n",
      " tf.__operators__.getitem (S  (1, 128)                 0         \n",
      " licingOpLambda)                                                 \n",
      "                                                                 \n",
      " dense (Dense)               (1, 1)                    129       \n",
      "                                                                 \n",
      " tf.compat.v1.squeeze (TFOpL  (1,)                     0         \n",
      " ambda)                                                          \n",
      "                                                                 \n",
      " model (Functional)          ((1, None, 10),           256802944 \n",
      "                              (10, 512))                         \n",
      "                                                                 \n",
      " model_1 (Functional)        (1, None, 10)             256802944 \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 256,874,241\n",
      "Trainable params: 256,874,241\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "model_path = results_path + model_name + '.h5'\n",
    "pNet_kmedoids = ProtoryNet()\n",
    "model = pNet_kmedoids.createModel(np.zeros((number_prototypes, 512)), number_prototypes)\n",
    "model.load_weights(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentence embedding using the finetune embedder in the model\n",
    "train_sentences_embedded = pNet_kmedoids.embed(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on testing data\n",
    "preds_test, accuracy_test = pNet_kmedoids.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5062240663900415"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After a couple of epochs the prototypes have not been able to move. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Oh God!',\n",
       " 1: \"I couldn't believe it he just left!\",\n",
       " 2: 'Oh God!',\n",
       " 3: 'Aw, come on.',\n",
       " 4: 'You come up with that yourself?',\n",
       " 5: 'Oh, come on.',\n",
       " 6: 'Oh my God!',\n",
       " 7: 'Oh, dear.',\n",
       " 8: 'Oh, dear.',\n",
       " 9: 'No, no!'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract final prototypes of the model\n",
    "final_prototypes = pNet_kmedoids.showPrototypes(train_sentences, train_sentences_embedded, number_prototypes, printOutput=False, return_prototypes = True)\n",
    "final_prototypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model using random initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /nfshome/students/cm007951/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "2022-07-28 16:15:39.063300: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-28 16:15:39.071484: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-28 16:15:39.072307: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-28 16:15:39.073271: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-28 16:15:39.073518: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-28 16:15:39.074303: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-28 16:15:39.075050: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-28 16:15:39.856610: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-28 16:15:39.857521: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-28 16:15:39.858292: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-28 16:15:39.859034: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21418 MB memory:  -> device: 0, name: GRID RTX6000-24C, pci bus id: 0000:02:04.0, compute capability: 7.5\n",
      "[db] model.input =  KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.string, name='input_1'), name='input_1', description=\"created by layer 'input_1'\")\n",
      "[db] protoLayerName =  proto_layer\n",
      "[db] protoLayer =  <protoryNet.ProtoryNet.createModel.<locals>.prototypeLayer object at 0x7f13223cbb90>\n",
      "[db] protoLayer.output =  (<KerasTensor: shape=(1, None, 10) dtype=float32 (created by layer 'proto_layer')>, <KerasTensor: shape=(10, 512) dtype=float32 (created by layer 'proto_layer')>)\n",
      "[db] distanceLayer.output =  KerasTensor(type_spec=TensorSpec(shape=(1, None, 10), dtype=tf.float32, name=None), name='distance_layer/PartitionedCall:0', description=\"created by layer 'distance_layer'\")\n",
      "Model: \"custom_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None,)]                 0         \n",
      "                                                                 \n",
      " keras_layer (KerasLayer)    (None, 512)               256797824 \n",
      "                                                                 \n",
      " tf.expand_dims (TFOpLambda)  (1, None, 512)           0         \n",
      "                                                                 \n",
      " proto_layer (prototypeLayer  ((1, None, 10),          5120      \n",
      " )                            (10, 512))                         \n",
      "                                                                 \n",
      " distance_layer (distanceLay  (1, None, 10)            0         \n",
      " er)                                                             \n",
      "                                                                 \n",
      " lstm (LSTM)                 [(1, None, 128),          71168     \n",
      "                              (1, 128),                          \n",
      "                              (1, 128)]                          \n",
      "                                                                 \n",
      " tf.__operators__.getitem (S  (1, 128)                 0         \n",
      " licingOpLambda)                                                 \n",
      "                                                                 \n",
      " dense (Dense)               (1, 1)                    129       \n",
      "                                                                 \n",
      " tf.compat.v1.squeeze (TFOpL  (1,)                     0         \n",
      " ambda)                                                          \n",
      "                                                                 \n",
      " model (Functional)          ((1, None, 10),           256802944 \n",
      "                              (10, 512))                         \n",
      "                                                                 \n",
      " model_1 (Functional)        (1, None, 10)             256802944 \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 256,874,241\n",
      "Trainable params: 256,874,241\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Initial prototypes execution time: 3.801942463715871\n",
      "Epoch  0\n",
      "i =   0\n",
      "2022-07-28 16:19:55.228574: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8201\n",
      "5/5 [==============================] - 10s 78ms/step - loss: 0.2792\n",
      "Evaluate on valid set:  0.498960498960499\n",
      "This is the best eval res, saving the model...\n",
      "saving model now = 2022-07-28 16:20:39.958933\n",
      "just saved\n",
      "i =   50\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.9072\n",
      "i =   100\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 1.0547\n",
      "i =   150\n",
      "5/5 [==============================] - 0s 78ms/step - loss: 0.9546\n",
      "i =   200\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.5646\n",
      "Evaluate on valid set:  0.498960498960499\n",
      "i =   250\n",
      "9/9 [==============================] - 1s 78ms/step - loss: 0.7634\n",
      "i =   300\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 0.7019\n",
      "i =   350\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.6473\n",
      "i =   400\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.9397\n",
      "Evaluate on valid set:  0.498960498960499\n",
      "i =   450\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 0.9220\n",
      "i =   500\n",
      "5/5 [==============================] - 0s 78ms/step - loss: 0.8138\n",
      "i =   550\n",
      "6/6 [==============================] - 0s 82ms/step - loss: 0.7525\n",
      "i =   600\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.5607\n",
      "Evaluate on valid set:  0.498960498960499\n",
      "i =   650\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.4954\n",
      "i =   700\n",
      "6/6 [==============================] - 0s 79ms/step - loss: 0.5978\n",
      "i =   750\n",
      "14/14 [==============================] - 1s 81ms/step - loss: 0.6186\n",
      "i =   800\n",
      "9/9 [==============================] - 1s 78ms/step - loss: 0.7972\n",
      "Evaluate on valid set:  0.498960498960499\n",
      "i =   850\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.8162\n",
      "i =   900\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.6954\n",
      "i =   950\n",
      "7/7 [==============================] - 1s 78ms/step - loss: 0.6633\n",
      "i =   1000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.6536\n",
      "Evaluate on valid set:  0.498960498960499\n",
      "i =   1050\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.5716\n",
      "i =   1100\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.6185\n",
      "i =   1150\n",
      "5/5 [==============================] - 0s 77ms/step - loss: 0.7153\n",
      "i =   1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 1s 80ms/step - loss: 0.6388\n",
      "Evaluate on valid set:  0.498960498960499\n",
      "i =   1250\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.8597\n",
      "i =   1300\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.9545\n",
      "i =   1350\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 0.5718\n",
      "i =   1400\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.8328\n",
      "Evaluate on valid set:  0.498960498960499\n",
      "i =   1450\n",
      "9/9 [==============================] - 1s 80ms/step - loss: 0.3756\n",
      "i =   1500\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.6003\n",
      "i =   1550\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.6977\n",
      "i =   1600\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.7843\n",
      "Evaluate on valid set:  0.498960498960499\n",
      "i =   1650\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.6352\n",
      "Epoch  1\n",
      "i =   0\n",
      "5/5 [==============================] - 0s 78ms/step - loss: 0.7524\n",
      "Evaluate on valid set:  0.498960498960499\n",
      "i =   50\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.6661\n",
      "i =   100\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.9191\n",
      "i =   150\n",
      "5/5 [==============================] - 0s 78ms/step - loss: 0.7823\n",
      "i =   200\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.5006\n",
      "Evaluate on valid set:  0.498960498960499\n",
      "i =   250\n",
      "9/9 [==============================] - 1s 80ms/step - loss: 0.6727\n",
      "i =   300\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.7500\n",
      "i =   350\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.6684\n",
      "i =   400\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.8075\n",
      "Evaluate on valid set:  0.498960498960499\n",
      "i =   450\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 0.8865\n",
      "i =   500\n",
      "5/5 [==============================] - 0s 77ms/step - loss: 0.8686\n",
      "i =   550\n",
      "6/6 [==============================] - 0s 78ms/step - loss: 0.6961\n",
      "i =   600\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.5562\n",
      "Evaluate on valid set:  0.498960498960499\n",
      "i =   650\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.5197\n",
      "i =   700\n",
      "6/6 [==============================] - 0s 79ms/step - loss: 0.5386\n",
      "i =   750\n",
      "14/14 [==============================] - 1s 82ms/step - loss: 0.5960\n",
      "i =   800\n",
      "9/9 [==============================] - 1s 78ms/step - loss: 0.8068\n",
      "Evaluate on valid set:  0.498960498960499\n",
      "i =   850\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.8347\n",
      "i =   900\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.7200\n",
      "i =   950\n",
      "7/7 [==============================] - 1s 77ms/step - loss: 0.6563\n",
      "i =   1000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.6629\n",
      "Evaluate on valid set:  0.5239085239085239\n",
      "This is the best eval res, saving the model...\n",
      "saving model now = 2022-07-28 16:50:03.293843\n",
      "just saved\n",
      "i =   1050\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5290\n",
      "i =   1100\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.6582\n",
      "i =   1150\n",
      "5/5 [==============================] - 0s 78ms/step - loss: 0.6967\n",
      "i =   1200\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 0.6306\n",
      "Evaluate on valid set:  0.5426195426195426\n",
      "This is the best eval res, saving the model...\n",
      "saving model now = 2022-07-28 16:52:44.518793\n",
      "just saved\n",
      "i =   1250\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.8593\n",
      "i =   1300\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.9117\n",
      "i =   1350\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 0.6216\n",
      "i =   1400\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.9210\n",
      "Evaluate on valid set:  0.498960498960499\n",
      "i =   1450\n",
      "9/9 [==============================] - 1s 82ms/step - loss: 0.3652\n",
      "i =   1500\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.5284\n",
      "i =   1550\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.6490\n",
      "i =   1600\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.6495\n",
      "Evaluate on valid set:  0.6153846153846154\n",
      "This is the best eval res, saving the model...\n",
      "saving model now = 2022-07-28 16:57:54.068342\n",
      "just saved\n",
      "i =   1650\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.5438\n",
      "{'train_time': 39.35897603034973, 'history_validation_accuracy': [0.498960498960499, 0.6153846153846154], 'best_validation_accuracy': 0.6153846153846154, 'initial_prototypes': {0: 'I called your house like four times.', 1: \"I don't think people even noticed.\", 2: \"I'm the victim.\", 3: \"But I can't just drop everything and leave.\", 4: 'Oh, some of the scripts were so spirited!', 5: \"How'd you do on the science test?\", 6: \"I'm going to look around.\", 7: 'No de-fense.', 8: 'Baxter?', 9: 'Poor girl how could you do a thing like that?'}, 'args': Namespace(dataset_path='datasets/cornell_corpus/cornell_prepro_characters_70train_20val_10test/', epochs=2, init_prototypes_seed=16, number_prototypes=10, results_path='results/protorynet_models/', results_prefix='cornell_prepro_characters_70train_20val_10test', sample_size_sentences=20000, type_init='random')}\n"
     ]
    }
   ],
   "source": [
    "# !python scripts_and_notebooks/train_protorynet.py --dataset_path=datasets/cornell_corpus/cornell_prepro_characters_70train_20val_10test/ --results_path=results/protorynet_models/ --results_prefix=cornell_prepro_characters_70train_20val_10test --epochs=2 --number_prototypes=10 --type_init=random --sample_size_sentences=20000 --init_prototypes_seed=16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path = 'results/protorynet_models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load results from the model\n",
    "model_name = 'cornell_prepro_characters_70train_20val_10test__2epochs__10prototypes__randomtype_init__20000sample_size_sentences__16init_prototypes_seed'\n",
    "model_random_results = pickle.load(open(results_path + model_name + '.pickle', 'rb'))\n",
    "\n",
    "# Extract number of prototypes\n",
    "number_prototypes = model_random_results['args'].number_prototypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With random initialization it is more probable to get heterogeneous initialization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'I called your house like four times.',\n",
       " 1: \"I don't think people even noticed.\",\n",
       " 2: \"I'm the victim.\",\n",
       " 3: \"But I can't just drop everything and leave.\",\n",
       " 4: 'Oh, some of the scripts were so spirited!',\n",
       " 5: \"How'd you do on the science test?\",\n",
       " 6: \"I'm going to look around.\",\n",
       " 7: 'No de-fense.',\n",
       " 8: 'Baxter?',\n",
       " 9: 'Poor girl how could you do a thing like that?'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_random_results['initial_prototypes']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we load the model to observe the prototypes after a couple of epochs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[db] model.input =  KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.string, name='input_1'), name='input_1', description=\"created by layer 'input_1'\")\n",
      "[db] protoLayerName =  proto_layer\n",
      "[db] protoLayer =  <protoryNet.ProtoryNet.createModel.<locals>.prototypeLayer object at 0x7f7c71741350>\n",
      "[db] protoLayer.output =  (<KerasTensor: shape=(1, None, 10) dtype=float32 (created by layer 'proto_layer')>, <KerasTensor: shape=(10, 512) dtype=float32 (created by layer 'proto_layer')>)\n",
      "[db] distanceLayer.output =  KerasTensor(type_spec=TensorSpec(shape=(1, None, 10), dtype=tf.float32, name=None), name='distance_layer/PartitionedCall:0', description=\"created by layer 'distance_layer'\")\n",
      "Model: \"custom_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None,)]                 0         \n",
      "                                                                 \n",
      " keras_layer (KerasLayer)    (None, 512)               256797824 \n",
      "                                                                 \n",
      " tf.expand_dims (TFOpLambda)  (1, None, 512)           0         \n",
      "                                                                 \n",
      " proto_layer (prototypeLayer  ((1, None, 10),          5120      \n",
      " )                            (10, 512))                         \n",
      "                                                                 \n",
      " distance_layer (distanceLay  (1, None, 10)            0         \n",
      " er)                                                             \n",
      "                                                                 \n",
      " lstm (LSTM)                 [(1, None, 128),          71168     \n",
      "                              (1, 128),                          \n",
      "                              (1, 128)]                          \n",
      "                                                                 \n",
      " tf.__operators__.getitem (S  (1, 128)                 0         \n",
      " licingOpLambda)                                                 \n",
      "                                                                 \n",
      " dense (Dense)               (1, 1)                    129       \n",
      "                                                                 \n",
      " tf.compat.v1.squeeze (TFOpL  (1,)                     0         \n",
      " ambda)                                                          \n",
      "                                                                 \n",
      " model (Functional)          ((1, None, 10),           256802944 \n",
      "                              (10, 512))                         \n",
      "                                                                 \n",
      " model_1 (Functional)        (1, None, 10)             256802944 \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 256,874,241\n",
      "Trainable params: 256,874,241\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "model_path = results_path + model_name + '.h5'\n",
    "pNet_random = ProtoryNet()\n",
    "model = pNet_random.createModel(np.zeros((number_prototypes, 512)), number_prototypes)\n",
    "model.load_weights(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentence embedding using the finetune embedder in the model\n",
    "train_sentences_embedded = pNet_random.embed(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on testing data\n",
    "preds_test, accuracy_test = pNet_random.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6099585062240664"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After a couple of epochs some prototypes start to change and the test accuracy is way better than when using kmedoids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'I called your house like four times.',\n",
       " 1: \"I don't think people even noticed.\",\n",
       " 2: \"I'm the victim.\",\n",
       " 3: \"But I can't just drop everything and leave.\",\n",
       " 4: \"He's a very proper actor.\",\n",
       " 5: \"How'd you do on the science test?\",\n",
       " 6: 'What are you looking at?',\n",
       " 7: 'No, and yes.',\n",
       " 8: '<u>No</u> mention of the Girlscout.',\n",
       " 9: 'Poor girl how could you do a thing like that?'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract final prototypes of the model\n",
    "final_prototypes = pNet_random.showPrototypes(train_sentences, train_sentences_embedded, number_prototypes, printOutput=False, return_prototypes = True)\n",
    "final_prototypes"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ProtoryNet_example.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
