{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"LIT_exploring.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyO1gKrsS0Qn/6Gg3uuQXAt9"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25177,"status":"ok","timestamp":1658680690946,"user":{"displayName":"Mariana Chaves","userId":"14956690162580527944"},"user_tz":-120},"id":"YyXBvrI4pfJT","outputId":"0c2d47b9-b8ee-469a-d4f0-f95d7972fa56"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3480,"status":"ok","timestamp":1658680694409,"user":{"displayName":"Mariana Chaves","userId":"14956690162580527944"},"user_tz":-120},"id":"qpVOYlZKsJaS","outputId":"335d410e-6a0a-4a7c-f7f1-d10fd79060be"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/Othercomputers/My Laptop/Documents/UCA DSAI/Internship 2/Code/text-models/scripts_and_notebooks\n"]}],"source":["%cd /content/drive/Othercomputers/My Laptop/Documents/UCA DSAI/Internship 2/Code/text-models/scripts_and_notebooks/"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1658680694411,"user":{"displayName":"Mariana Chaves","userId":"14956690162580527944"},"user_tz":-120},"id":"OZqG427t2mBK","outputId":"86732d27-0a87-492b-914e-1ab20dc56b8b"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/Othercomputers/My Laptop/Documents/UCA DSAI/Internship 2/Code/text-models\n"]}],"source":["%cd .."]},{"cell_type":"code","source":["pip install lit_nlp"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ib4_dIPSFmZc","executionInfo":{"status":"ok","timestamp":1658680950147,"user_tz":-120,"elapsed":12033,"user":{"displayName":"Mariana Chaves","userId":"14956690162580527944"}},"outputId":"27936f82-dccb-45be-f0ac-a9fc626d4d35"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting lit_nlp\n","  Downloading lit_nlp-0.4.1-py3-none-any.whl (746 kB)\n","\u001b[K     |████████████████████████████████| 746 kB 4.3 MB/s \n","\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from lit_nlp) (1.0.2)\n","Requirement already satisfied: portpicker in /usr/local/lib/python3.7/dist-packages (from lit_nlp) (1.3.9)\n","Requirement already satisfied: Werkzeug in /usr/local/lib/python3.7/dist-packages (from lit_nlp) (1.0.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from lit_nlp) (1.3.5)\n","Collecting sacrebleu\n","  Downloading sacrebleu-2.1.0-py3-none-any.whl (92 kB)\n","\u001b[K     |████████████████████████████████| 92 kB 10.8 MB/s \n","\u001b[?25hCollecting umap-learn\n","  Downloading umap-learn-0.5.3.tar.gz (88 kB)\n","\u001b[K     |████████████████████████████████| 88 kB 7.6 MB/s \n","\u001b[?25hRequirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from lit_nlp) (21.4.0)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from lit_nlp) (1.2.0)\n","Collecting ml-collections\n","  Downloading ml_collections-0.1.1.tar.gz (77 kB)\n","\u001b[K     |████████████████████████████████| 77 kB 6.6 MB/s \n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from lit_nlp) (1.7.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from lit_nlp) (1.21.6)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from ml-collections->lit_nlp) (3.13)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from ml-collections->lit_nlp) (1.15.0)\n","Requirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from ml-collections->lit_nlp) (0.5.5)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->lit_nlp) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->lit_nlp) (2022.1)\n","Collecting portalocker\n","  Downloading portalocker-2.5.1-py2.py3-none-any.whl (15 kB)\n","Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from sacrebleu->lit_nlp) (2022.6.2)\n","Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu->lit_nlp) (0.8.10)\n","Collecting colorama\n","  Downloading colorama-0.4.5-py2.py3-none-any.whl (16 kB)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->lit_nlp) (1.1.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->lit_nlp) (3.1.0)\n","Requirement already satisfied: numba>=0.49 in /usr/local/lib/python3.7/dist-packages (from umap-learn->lit_nlp) (0.51.2)\n","Collecting pynndescent>=0.5\n","  Downloading pynndescent-0.5.7.tar.gz (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 47.3 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from umap-learn->lit_nlp) (4.64.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.49->umap-learn->lit_nlp) (57.4.0)\n","Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.49->umap-learn->lit_nlp) (0.34.0)\n","Building wheels for collected packages: ml-collections, umap-learn, pynndescent\n","  Building wheel for ml-collections (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ml-collections: filename=ml_collections-0.1.1-py3-none-any.whl size=94524 sha256=8c675587ea3375a69d44e3d5d5eb42e939dd5e79eef97d634e6efdebd4c2fe3d\n","  Stored in directory: /root/.cache/pip/wheels/b7/da/64/33c926a1b10ff19791081b705879561b715a8341a856a3bbd2\n","  Building wheel for umap-learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for umap-learn: filename=umap_learn-0.5.3-py3-none-any.whl size=82829 sha256=ec6785bd9f981e6fd0ce778d818ca03c1960d68315402722a2d623490bac63f7\n","  Stored in directory: /root/.cache/pip/wheels/b3/52/a5/1fd9e3e76a7ab34f134c07469cd6f16e27ef3a37aeff1fe821\n","  Building wheel for pynndescent (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pynndescent: filename=pynndescent-0.5.7-py3-none-any.whl size=54286 sha256=16ea0744c61707e5b74256e5a5ab3d0411c5592bf6e461dcc7c2d421fd6f5d90\n","  Stored in directory: /root/.cache/pip/wheels/7f/2a/f8/7bd5dcec71bd5c669f6f574db3113513696b98f3f9b51f496c\n","Successfully built ml-collections umap-learn pynndescent\n","Installing collected packages: pynndescent, portalocker, colorama, umap-learn, sacrebleu, ml-collections, lit-nlp\n","Successfully installed colorama-0.4.5 lit-nlp-0.4.1 ml-collections-0.1.1 portalocker-2.5.1 pynndescent-0.5.7 sacrebleu-2.1.0 umap-learn-0.5.3\n"]}]},{"cell_type":"code","source":["!python scripts_and_notebooks/lit/run.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UQNNLIKtFWZu","executionInfo":{"status":"ok","timestamp":1658683129068,"user_tz":-120,"elapsed":42153,"user":{"displayName":"Mariana Chaves","userId":"14956690162580527944"}},"outputId":"e7a902b0-ab52-4ba8-ad86-1e42ddf63f52"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["2022-07-24 17:18:47.449821: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n","Traceback (most recent call last):\n","  File \"scripts_and_notebooks/lit/run.py\", line 121, in <module>\n","    main()\n","  File \"scripts_and_notebooks/lit/run.py\", line 117, in main\n","    lit_demo = lit_nlp.dev_server.Server(models, datasets, port=4321)\n","AttributeError: module 'lit_nlp' has no attribute 'dev_server'\n"]}]},{"cell_type":"code","source":["import lit_nlp\n","import pandas as pd\n","import gensim\n","from lit_nlp.api import dataset as lit_dataset\n","from lit_nlp.api import types as lit_types\n","from lit_nlp.api import model as lit_model\n","from lit_nlp import notebook\n","from sklearn.model_selection import train_test_split\n","# from lit_nlp.examples.models import model_utils\n","from lit_nlp.lib import utils\n","from typing import Iterable, Iterator\n","import tensorflow as tf"],"metadata":{"id":"xdK5FrCcPDXL","executionInfo":{"status":"ok","timestamp":1658683618066,"user_tz":-120,"elapsed":13907,"user":{"displayName":"Mariana Chaves","userId":"14956690162580527944"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["class RNNModel(lit_model.Model):\n","    \"\"\"Wrapper for the RNN model.\"\"\"\n","\n","    LABELS = ['Male', 'Female']\n","\n","    def __init__(self, path_to_models, **kw):\n","        # Load the model into memory so we're ready for interactive use.\n","        # FIXME: I've omitted `+ model_name + '.h5'` from the argument and which will probably break it\n","        self._model = tf.keras.models.load_model(path_to_models)\n","\n","    # LIT API implementations\n","    def input_spec(self):\n","        \"\"\"Describe the inputs to the model.\"\"\"\n","        return {\n","            'dialogs': lit_types.TextSegment()\n","        }\n","\n","    def output_spec(self):\n","        \"\"\"Describe the model outputs.\"\"\"\n","        return {\n","            # The 'parent' keyword tells LIT where to look for gold labels when computing metrics.\n","            'probas': lit_types.MulticlassPreds(vocab = self.LABELS, parent='label'),\n","        }\n","\n","    # TODO: predicting as a batch should be faster\n","    # def predict(self, inputs: Iterable[Input]) -> Iterator[Preds]:\n","    # def predict(self, inputs: Iterable[tf.keras.layers.Input]):\n","    def predict(self, inputs):\n","        \"\"\"Predict on a stream of examples.\"\"\"\n","        examples = [d for d in inputs]  # any custom preprocessing (right now this does nothing)\n","        # returns a dict for each input\n","        # TODO: apply a softmax to the output\n","        return [{'probas': self._model.predict(example)} for example in examples]\n","    \n","    def predict_minibatch(self, inputs):\n","      raise ValueError(\"shit\")\n","\n","\n","class GenderData(lit_dataset.Dataset):\n","    # IMPROVE ME\n","    \"\"\"Loader of movie dialog dataset\"\"\"\n","\n","    LABELS = ['Male', 'Female']\n","\n","    # TODO: It should be possible to take the dataset path as an argument\n","    def __init__(self, path_to_data):\n","        # LOAD DATASET\n","        data = pd.read_csv(path_to_data)\n","\n","        # Load word2vec trained model\n","        w2v = gensim.models.KeyedVectors.load(\"results/cornell_prepro.wordvectors\", mmap='r')\n","        # word2vec vocabulary\n","        w2v_vocabulary = list(w2v.vocab.keys())\n","\n","        # Keep only the words that are in the vocabulary\n","        # Sentences to lists of words\n","        docs = [d.lower().split() for d in data['text']]\n","        # Keep only the words that are in the w2v vocabulary (These were the words that appeared 5 times or more times)\n","        docs = [[word for word in doc if word in w2v_vocabulary] for doc in docs]\n","        # Join the list of strings into sentences\n","        docs = [' '.join(doc) for doc in docs]\n","\n","        # Train, validation, test split\n","        train_split = 0.7\n","        val_split = 0.2\n","        test_split = 1 - train_split - val_split\n","\n","        X = docs\n","        # y = np.array((data['gender'] == 'F').astype('int'))\n","        y = list((data['gender'] == 'F').astype('int'))\n","\n","        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_split, random_state = 32, stratify = y)\n","        X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = val_split/(train_split + val_split), random_state = 32, stratify = y_train)\n","\n","        self._examples = [{\n","                'dialogs': x,\n","                'label': self.LABELS[y],\n","            } for x, y in zip(X_test, y_test)]\n","\n","    def spec(self):\n","        return {\n","            'dialogs': lit_types.TextSegment(),\n","            'label': lit_types.CategoryLabel(vocab=self.LABELS)\n","        }"],"metadata":{"id":"JzUTTGTXOtty","executionInfo":{"status":"ok","timestamp":1658683799433,"user_tz":-120,"elapsed":429,"user":{"displayName":"Mariana Chaves","userId":"14956690162580527944"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["path_to_models = 'results/models/'\n","\n","# MulitiNLIData implements the Dataset API\n","datasets = {\n","    'cornell_proprocessed_characters': GenderData('datasets/cornell_corpus/cornell_prepro_characters.csv'),\n","}\n","\n","# NLIModel implements the Model API\n","models = {\n","    'model_rnn': RNNModel(path_to_models + 'textvectorizer_embedding128_globalmaxpooling_dense50_dense10_sigmoid' + '.h5'),\n","}\n","\n","widget = notebook.LitWidget(models, datasets, height=800)\n","\n","# lit_demo = lit_nlp.dev_server.Server(models, datasets, port=4321)\n","# lit_demo.serve()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":397},"id":"AcOJTxdgPJsK","executionInfo":{"status":"error","timestamp":1658683837345,"user_tz":-120,"elapsed":34997,"user":{"displayName":"Mariana Chaves","userId":"14956690162580527944"}},"outputId":"eb134c6f-b811-45aa-fe09-bc577dd9a50b"},"execution_count":24,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-24-3580b99b65df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m }\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mwidget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnotebook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLitWidget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m800\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# lit_demo = lit_nlp.dev_server.Server(models, datasets, port=4321)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/lit_nlp/notebook.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, height, render, proxy_url, layouts, *args, **kw)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0mlit_demo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdev_server\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mServer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayouts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mapp_flags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_server\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwsgi_serving\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNotebookWsgiServer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlit_demo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_height\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_proxy_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproxy_url\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/lit_nlp/dev_server.py\u001b[0m in \u001b[0;36mserve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     88\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_lit_logo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Starting LIT server...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m       \u001b[0mapp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlit_app\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLitApp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_app_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_app_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m       \u001b[0;31m# If using a separate server program to serve the app, such as gunicorn,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/lit_nlp/app.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, models, datasets, generators, interpreters, annotators, layouts, data_dir, warm_start, warm_projections, client_root, demo_mode, default_layout, canonical_url, page_title, development_demo)\u001b[0m\n\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mwarm_start\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_warm_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwarm_start\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/lit_nlp/app.py\u001b[0m in \u001b[0;36m_warm_start\u001b[0;34m(self, rate)\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m           \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfull_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m         \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_preds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'inputs'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_warm_projections\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpreters\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mText\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/lit_nlp/app.py\u001b[0m in \u001b[0;36m_get_preds\u001b[0;34m(self, data, model, dataset_name, requested_types, **unused_kw)\u001b[0m\n\u001b[1;32m    180\u001b[0m       \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mJsonDict\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0mcontaining\u001b[0m \u001b[0mrequested\u001b[0m \u001b[0mfields\u001b[0m \u001b[0mof\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m     \"\"\"\n\u001b[0;32m--> 182\u001b[0;31m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'inputs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;31m# Figure out what to return to the frontend.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/lit_nlp/app.py\u001b[0m in \u001b[0;36m_predict\u001b[0;34m(self, inputs, model_name, dataset_name)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;34m\"\"\"Run model predictions.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     return list(self._models[model_name].predict_with_metadata(\n\u001b[0;32m--> 147\u001b[0;31m         inputs, dataset_name=dataset_name))\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_save_datapoints\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mText\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mText\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/lit_nlp/lib/caching.py\u001b[0m in \u001b[0;36mpredict_with_metadata\u001b[0;34m(self, *args, **kw)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;31m# models are generally compute-bound anyway.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict_with_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/lit_nlp/lib/caching.py\u001b[0m in \u001b[0;36m_predict_with_metadata\u001b[0;34m(self, indexed_inputs, dataset_name, **kw)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexed_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmiss_idxs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Prepared %d inputs for model\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m     \u001b[0mmodel_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_with_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Received %d predictions from model\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     assert len(model_preds) == len(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/lit_nlp/api/model.py\u001b[0m in \u001b[0;36mpredict_with_metadata\u001b[0;34m(self, indexed_inputs, **kw)\u001b[0m\n\u001b[1;32m    216\u001b[0m                             **kw) -> Iterator[JsonDict]:\n\u001b[1;32m    217\u001b[0m     \u001b[0;34m\"\"\"As predict(), but inputs are IndexedInput.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindexed_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-23-898c586fe791>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;31m# returns a dict for each input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m# TODO: apply a softmax to the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'probas'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mexample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexamples\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_minibatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-23-898c586fe791>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;31m# returns a dict for each input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m# TODO: apply a softmax to the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'probas'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mexample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexamples\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_minibatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mselect_data_adapter\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    985\u001b[0m         \u001b[0;34m\"Failed to find data adapter that can handle \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    986\u001b[0m         \"input: {}, {}\".format(\n\u001b[0;32m--> 987\u001b[0;31m             _type_name(x), _type_name(y)))\n\u001b[0m\u001b[1;32m    988\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madapter_cls\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m     raise RuntimeError(\n","\u001b[0;31mValueError\u001b[0m: Failed to find data adapter that can handle input: (<class 'dict'> containing {\"<class 'str'>\"} keys and {\"<class 'str'>\"} values), <class 'NoneType'>"]}]},{"cell_type":"code","source":["widget.render()"],"metadata":{"id":"ipzlMi8xPlUI"},"execution_count":null,"outputs":[]}]}