{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Autor: Mariana Chaves**\n",
    " \n",
    "**Date: July 2022**\n",
    "\n",
    "This notebooks reproduces the example presented by the authors of ProtoryNet in their paper and their [github repository](https://github.com/dathong/ProtoryNet), where they classify positive and negative reviews. \n",
    "We show that after a couple of epochs the model achieves 93.56% of accuracy. \n",
    "Nevertheless, the trained prototypes and their scores suggest that all prototypes are linked to the category \"positive\" almost to the same degree.\n",
    "With such prototypes one would expect the the model would classify all samples as \"positive\".\n",
    "Hence, even correct classifications seem unrelated to the prototypes.\n",
    "It seems that, after mapping each sentence to its active prototype, the model is still taking some decisions which remain occluded in the layers that follow the prototype layer.\n",
    "\n",
    "This notebook is largely inspired by the example presented by the authors of ProtoryNet in their [github repository](https://github.com/dathong/ProtoryNet)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 36,
     "status": "ok",
     "timestamp": 1642361175331,
     "user": {
      "displayName": "Mariana Chaves",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GitK6a8J23ZNS4lannJlrPyUTG-wmSWzMTrridp7OI=s64",
      "userId": "14956690162580527944"
     },
     "user_tz": -60
    },
    "id": "KGU7rAmNfmjF"
   },
   "outputs": [],
   "source": [
    "#import neccesary packages\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Concatenate, Dense, Input, LSTM, Embedding, Dropout, Activation, GRU, Flatten\n",
    "from datetime import datetime\n",
    "from scipy.spatial import distance_matrix\n",
    "import sys\n",
    "import time\n",
    "sys.path.append('../src/protoryNet/')\n",
    "from protoryNet import ProtoryNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go to main directory\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6IkGwcJaN4f_"
   },
   "source": [
    "# Import datasets (original example of the hotel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the same dataset as the authors of ProtoryNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1642361179149,
     "user": {
      "displayName": "Mariana Chaves",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GitK6a8J23ZNS4lannJlrPyUTG-wmSWzMTrridp7OI=s64",
      "userId": "14956690162580527944"
     },
     "user_tz": -60
    },
    "id": "XqtOqokrfsBg"
   },
   "outputs": [],
   "source": [
    "#directory of the datasets. Github provides these files in the form of pickle files\n",
    "#dir = \"../datasets/hotel/\"\n",
    "# dir = \"/content/drive/Othercomputers/My Laptop/Documents/UCA DSAI/Semester 3/Research project/ProtoryNet/datasets/hotel/\"\n",
    "dir = \"/nfshome/students/cm007951/protorynet/datasets/hotel/\"\n",
    "with open (dir + 'y_train', 'rb') as fp:\n",
    "    y_train = pickle.load(fp)\n",
    "\n",
    "with open (dir + 'train_not_clean', 'rb') as fp:\n",
    "    train_not_clean = pickle.load(fp)\n",
    "\n",
    "with open (dir + 'test_not_clean', 'rb') as fp:\n",
    "    test_not_clean = pickle.load(fp)\n",
    "\n",
    "with open (dir + 'y_test', 'rb') as fp:\n",
    "    y_test = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1642361180667,
     "user": {
      "displayName": "Mariana Chaves",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GitK6a8J23ZNS4lannJlrPyUTG-wmSWzMTrridp7OI=s64",
      "userId": "14956690162580527944"
     },
     "user_tz": -60
    },
    "id": "xdZhXzbERuDY",
    "outputId": "b99e27f2-674d-4459-bea6-65ba5d98a4a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"RENT A STEAM CLEANER. The location is very, very inconvenient, but I am sure that is nothing they can help, it is just how the city has grown around their location. I would have rated the room as a 4 or 5 for clean if the sofa was not so disgusting. I literally covered it with a sheet just to sit on it. There was not one inch of surface that was not covered with a greasy/dirty stain. I would have switched rooms if I hadn't already unloaded all of my stuff in the rain before I turned on the lights to reveal the nasty sofa. Otherwise, the room was clean and comfortable. It would be worth a couple of hundred dollars to get a steam cleaner and clean the sofas in each room. Not to mention how unsanitary it is\", \"Great hotel and staff - recommend. I came in late after a long drive from Vegas ending in a whole lot of highway exits and concentration to get to Napa. I was greeted by a friendly night staff who was expecting me, and (not sure of his name) made me feel more relaxed immediately. I even got a little welcome pack with a snack and water. That was much appreciated.Breakfast was not included, fruit and granola bars were out in the lobby. A hotel discount was offered at the friendly Denny's next door. My room was quiet and all 3 of the morning staff were incredibly helpful the next morning helping me map out my day of driving, and helping me choose and book my next hotels. The hotel is a convienent location, not too far off the main highway. Near all services and malls if needed.We are glad you enjoyed your stay with us and look foward to seeing you on your next visit to the Napa Valley\"]\n",
      "[1 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3606"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_not_clean[:2])\n",
    "print(y_train[:2])\n",
    "len(train_not_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xct3r6rdOLev"
   },
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 440,
     "status": "ok",
     "timestamp": 1642361184498,
     "user": {
      "displayName": "Mariana Chaves",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GitK6a8J23ZNS4lannJlrPyUTG-wmSWzMTrridp7OI=s64",
      "userId": "14956690162580527944"
     },
     "user_tz": -60
    },
    "id": "TEbpMg8ygFxV"
   },
   "outputs": [],
   "source": [
    "#this method is to split the paragraphs into sentences\n",
    "def gen_sents(para):\n",
    "    res = []\n",
    "    for p in para:\n",
    "        sents = p.split(\".\")\n",
    "        res.append(sents)\n",
    "    return res\n",
    "\n",
    "\n",
    "train_noclean_sents = gen_sents(train_not_clean)\n",
    "test_noclean_sents = gen_sents(test_not_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 241,
     "status": "ok",
     "timestamp": 1642361187647,
     "user": {
      "displayName": "Mariana Chaves",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GitK6a8J23ZNS4lannJlrPyUTG-wmSWzMTrridp7OI=s64",
      "userId": "14956690162580527944"
     },
     "user_tz": -60
    },
    "id": "Q7tvAjjzOJWp",
    "outputId": "36757f74-b5f0-4b86-8c45-31cdf178d700"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['RENT A STEAM CLEANER',\n",
       "  ' The location is very, very inconvenient, but I am sure that is nothing they can help, it is just how the city has grown around their location',\n",
       "  ' I would have rated the room as a 4 or 5 for clean if the sofa was not so disgusting',\n",
       "  ' I literally covered it with a sheet just to sit on it',\n",
       "  ' There was not one inch of surface that was not covered with a greasy/dirty stain',\n",
       "  \" I would have switched rooms if I hadn't already unloaded all of my stuff in the rain before I turned on the lights to reveal the nasty sofa\",\n",
       "  ' Otherwise, the room was clean and comfortable',\n",
       "  ' It would be worth a couple of hundred dollars to get a steam cleaner and clean the sofas in each room',\n",
       "  ' Not to mention how unsanitary it is'],\n",
       " ['Great hotel and staff - recommend',\n",
       "  ' I came in late after a long drive from Vegas ending in a whole lot of highway exits and concentration to get to Napa',\n",
       "  ' I was greeted by a friendly night staff who was expecting me, and (not sure of his name) made me feel more relaxed immediately',\n",
       "  ' I even got a little welcome pack with a snack and water',\n",
       "  ' That was much appreciated',\n",
       "  'Breakfast was not included, fruit and granola bars were out in the lobby',\n",
       "  \" A hotel discount was offered at the friendly Denny's next door\",\n",
       "  ' My room was quiet and all 3 of the morning staff were incredibly helpful the next morning helping me map out my day of driving, and helping me choose and book my next hotels',\n",
       "  ' The hotel is a convienent location, not too far off the main highway',\n",
       "  ' Near all services and malls if needed',\n",
       "  'We are glad you enjoyed your stay with us and look foward to seeing you on your next visit to the Napa Valley']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_noclean_sents[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 276,
     "status": "ok",
     "timestamp": 1642361208493,
     "user": {
      "displayName": "Mariana Chaves",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GitK6a8J23ZNS4lannJlrPyUTG-wmSWzMTrridp7OI=s64",
      "userId": "14956690162580527944"
     },
     "user_tz": -60
    },
    "id": "nNM0Ud6CjIUw",
    "outputId": "eefbe444-b954-4520-c5f2-8e2650498247"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_noclean_sents  902 7 ['Share your room with roach or bug', ' Roach in the room but the staff said its just a bug not a roach, like that made it any better', ' Big hole in the bathroom wall were this bug/roach came out of', ' Wonder what other rodent will come out of the wall', 'Thank you for providing us with your feedback', ' I would like to apologize for any of the inconveniences you may have experienced during your time with us', ' I wish that I had been notified of your concerns before you had checked out and I would like to apologize on behalf of our staff']\n",
      "y_train:  [1, 1, 1, 0, 1, 1, 0, 0, 1, 1]\n",
      "y_test:  [0, 0, 1, 1, 0, 1, 0, 0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "x_train = train_noclean_sents\n",
    "x_test = test_noclean_sents\n",
    "\n",
    "#Make sure the label values are integers\n",
    "y_train = [int(y) for y in y_train]\n",
    "y_test = [int(y) for y in y_test]\n",
    "\n",
    "\n",
    "print('test_noclean_sents ', len(test_noclean_sents), len(test_noclean_sents[0]), test_noclean_sents[0])\n",
    "print('y_train: ', y_train[:10])\n",
    "print('y_test: ', y_test[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16231,
     "status": "ok",
     "timestamp": 1642361275419,
     "user": {
      "displayName": "Mariana Chaves",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GitK6a8J23ZNS4lannJlrPyUTG-wmSWzMTrridp7OI=s64",
      "userId": "14956690162580527944"
     },
     "user_tz": -60
    },
    "id": "V7J7G3engGRo",
    "outputId": "a0023985-bbc3-4a5c-b1cf-58df4fe831cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module https://tfhub.dev/google/universal-sentence-encoder/4 loaded\n"
     ]
    }
   ],
   "source": [
    "#import Google Sentence encoder, to convert sentences into vector values\n",
    "module_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\"\n",
    "model = hub.load(module_url)\n",
    "print(\"module %s loaded\" % module_url)\n",
    "\n",
    "def embed(input):\n",
    "    return model(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take the first 10000 reviews of the training set and embed them using Google Sentence Encoder.\n",
    "We cannot take all reviews because later we use k-medoids, which runs into memery issues if it has too many data points.\n",
    "Each review can contain more than one sentence, that's why the 1st dimention of the object is 41996. \n",
    "512 corresponds to the size of the latent space.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41996, 512)\n"
     ]
    }
   ],
   "source": [
    "sample_sentences = []\n",
    "for p in train_noclean_sents[:10000]:\n",
    "    sample_sentences.extend(p)\n",
    "\n",
    "#compute vector values of sentences\n",
    "sample_sent_vect = embed(sample_sentences)\n",
    "# print(sample_sent_vect)\n",
    "print(sample_sent_vect.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 243,
     "status": "ok",
     "timestamp": 1642361634401,
     "user": {
      "displayName": "Mariana Chaves",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GitK6a8J23ZNS4lannJlrPyUTG-wmSWzMTrridp7OI=s64",
      "userId": "14956690162580527944"
     },
     "user_tz": -60
    },
    "id": "6Y-O_e0IXZYA",
    "outputId": "05011bdf-b791-4b74-fc0d-e186e4ec4a88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3606\n",
      "11747\n",
      "['RENT A STEAM CLEANER', ' The location is very, very inconvenient, but I am sure that is nothing they can help, it is just how the city has grown around their location', ' I would have rated the room as a 4 or 5 for clean if the sofa was not so disgusting', ' I literally covered it with a sheet just to sit on it', ' There was not one inch of surface that was not covered with a greasy/dirty stain', \" I would have switched rooms if I hadn't already unloaded all of my stuff in the rain before I turned on the lights to reveal the nasty sofa\", ' Otherwise, the room was clean and comfortable', ' It would be worth a couple of hundred dollars to get a steam cleaner and clean the sofas in each room', ' Not to mention how unsanitary it is']\n",
      "['RENT A STEAM CLEANER', ' The location is very, very inconvenient, but I am sure that is nothing they can help, it is just how the city has grown around their location', ' I would have rated the room as a 4 or 5 for clean if the sofa was not so disgusting', ' I literally covered it with a sheet just to sit on it', ' There was not one inch of surface that was not covered with a greasy/dirty stain', \" I would have switched rooms if I hadn't already unloaded all of my stuff in the rain before I turned on the lights to reveal the nasty sofa\", ' Otherwise, the room was clean and comfortable', ' It would be worth a couple of hundred dollars to get a steam cleaner and clean the sofas in each room', ' Not to mention how unsanitary it is', 'Great hotel and staff - recommend']\n"
     ]
    }
   ],
   "source": [
    "# We put each sentence separately, that's why the number increases\n",
    "print(len(train_noclean_sents))\n",
    "print(len(sample_sentences))\n",
    "print(train_noclean_sents[0])\n",
    "print(sample_sentences[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aWP5cKX6OQtu"
   },
   "source": [
    "# Prototype initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The initial prototypes are centroids chosen by k-medoids.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4698,
     "status": "ok",
     "timestamp": 1642361914768,
     "user": {
      "displayName": "Mariana Chaves",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GitK6a8J23ZNS4lannJlrPyUTG-wmSWzMTrridp7OI=s64",
      "userId": "14956690162580527944"
     },
     "user_tz": -60
    },
    "id": "-72NuWCJgKbf",
    "outputId": "6c9c5593-e62e-4fd8-a020-8dff66a90fc5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 512)\n"
     ]
    }
   ],
   "source": [
    "k_protos, vect_size = 10, 512 #512 because we have the sentences are transformed into vectors of size 512\n",
    "kmedoids = KMedoids(n_clusters=k_protos, random_state=0).fit(sample_sent_vect)\n",
    "k_cents = kmedoids.cluster_centers_\n",
    "print(k_cents.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 305,
     "status": "ok",
     "timestamp": 1642361926823,
     "user": {
      "displayName": "Mariana Chaves",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GitK6a8J23ZNS4lannJlrPyUTG-wmSWzMTrridp7OI=s64",
      "userId": "14956690162580527944"
     },
     "user_tz": -60
    },
    "id": "ADkVaRe3Zhdd",
    "outputId": "97efeeed-fb14-47fb-bebf-418b573a9ba6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-3.0867750e-02 -4.0647369e-02 -6.2585823e-02 ... -4.3438803e-02\n",
      "   2.1392105e-02 -1.9520901e-02]\n",
      " [ 2.4763636e-02 -7.5006582e-02 -5.5820044e-02 ... -1.8545931e-02\n",
      "   6.3773416e-02  2.4646815e-02]\n",
      " [-2.7673064e-02 -1.2406837e-03 -4.8067428e-02 ... -8.5736131e-03\n",
      "   4.5512866e-02  1.8920101e-02]\n",
      " ...\n",
      " [-3.9867338e-02  1.2999296e-02 -4.1530743e-02 ... -2.1137370e-02\n",
      "  -2.4923310e-04  5.6575678e-02]\n",
      " [-3.8432319e-02 -2.3378124e-03 -2.9857373e-02 ... -5.9871352e-05\n",
      "   9.3568325e-02  2.2465114e-02]\n",
      " [-1.7571883e-02 -4.6657540e-02 -2.1202940e-02 ... -4.3001492e-04\n",
      "   7.2558373e-02  3.1543452e-02]]\n"
     ]
    }
   ],
   "source": [
    "print(k_cents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KI9aT_tZOY3Q"
   },
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 345,
     "status": "ok",
     "timestamp": 1642362244125,
     "user": {
      "displayName": "Mariana Chaves",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GitK6a8J23ZNS4lannJlrPyUTG-wmSWzMTrridp7OI=s64",
      "userId": "14956690162580527944"
     },
     "user_tz": -60
    },
    "id": "8NNK6ORKhtRV"
   },
   "outputs": [],
   "source": [
    "pNet = ProtoryNet() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4696,
     "status": "ok",
     "timestamp": 1642362251740,
     "user": {
      "displayName": "Mariana Chaves",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GitK6a8J23ZNS4lannJlrPyUTG-wmSWzMTrridp7OI=s64",
      "userId": "14956690162580527944"
     },
     "user_tz": -60
    },
    "id": "LOQ5g8igi7HW",
    "outputId": "95c6fdd6-167c-4580-9f91-26af08e158b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[db] model.input =  KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.string, name='input_1'), name='input_1', description=\"created by layer 'input_1'\")\n",
      "[db] protoLayerName =  proto_layer\n",
      "[db] protoLayer =  <protoryNet.ProtoryNet.createModel.<locals>.prototypeLayer object at 0x7f9a512e4490>\n",
      "[db] protoLayer.output =  (<KerasTensor: shape=(1, None, 10) dtype=float32 (created by layer 'proto_layer')>, <KerasTensor: shape=(10, 512) dtype=float32 (created by layer 'proto_layer')>)\n",
      "[db] distanceLayer.output =  KerasTensor(type_spec=TensorSpec(shape=(1, None, 10), dtype=tf.float32, name=None), name='distance_layer/PartitionedCall:0', description=\"created by layer 'distance_layer'\")\n",
      "Model: \"custom_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None,)]                 0         \n",
      "                                                                 \n",
      " keras_layer (KerasLayer)    (None, 512)               256797824 \n",
      "                                                                 \n",
      " tf.expand_dims (TFOpLambda)  (1, None, 512)           0         \n",
      "                                                                 \n",
      " proto_layer (prototypeLayer  ((1, None, 10),          5120      \n",
      " )                            (10, 512))                         \n",
      "                                                                 \n",
      " distance_layer (distanceLay  (1, None, 10)            0         \n",
      " er)                                                             \n",
      "                                                                 \n",
      " lstm (LSTM)                 [(1, None, 128),          71168     \n",
      "                              (1, 128),                          \n",
      "                              (1, 128)]                          \n",
      "                                                                 \n",
      " tf.__operators__.getitem (S  (1, 128)                 0         \n",
      " licingOpLambda)                                                 \n",
      "                                                                 \n",
      " dense (Dense)               (1, 1)                    129       \n",
      "                                                                 \n",
      " tf.compat.v1.squeeze (TFOpL  (1,)                     0         \n",
      " ambda)                                                          \n",
      "                                                                 \n",
      " model (Functional)          ((1, None, 10),           256802944 \n",
      "                              (10, 512))                         \n",
      "                                                                 \n",
      " model_1 (Functional)        (1, None, 10)             256802944 \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 256,874,241\n",
      "Trainable params: 256,874,241\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = pNet.createModel(k_cents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8kiIGwFTqGEZ",
    "outputId": "842f8661-832d-4ed2-c1d5-e483a3132d1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0\n",
      "i =   0\n",
      "1/1 [==============================] - 11s 11s/step - loss: 0.2301\n",
      "Evaluate on valid set:  0.5144124168514412\n",
      "This is the best eval res, saving the model...\n",
      "saving model now = 2022-07-21 11:12:10.517628\n",
      "just saved\n",
      "i =   50\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2405\n",
      "i =   100\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.3593\n",
      "i =   150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4773\n",
      "i =   200\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.1163\n",
      "Evaluate on valid set:  0.5144124168514412\n",
      "i =   250\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.9968\n",
      "i =   300\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4902\n",
      "i =   350\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.5020\n",
      "i =   400\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.1189\n",
      "Evaluate on valid set:  0.5144124168514412\n",
      "i =   450\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3508\n",
      "i =   500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.5754\n",
      "i =   550\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.2396\n",
      "i =   600\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3711\n",
      "Evaluate on valid set:  0.5831485587583148\n",
      "This is the best eval res, saving the model...\n",
      "saving model now = 2022-07-21 11:17:40.442091\n",
      "just saved\n",
      "i =   650\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4630\n",
      "i =   700\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.6184\n",
      "i =   750\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.8648\n",
      "i =   800\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.5595\n",
      "Evaluate on valid set:  0.770509977827051\n",
      "This is the best eval res, saving the model...\n",
      "saving model now = 2022-07-21 11:19:52.479014\n",
      "just saved\n",
      "i =   850\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0907\n",
      "i =   900\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.2870\n",
      "i =   950\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0976\n",
      "i =   1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.5831\n",
      "Evaluate on valid set:  0.8381374722838137\n",
      "This is the best eval res, saving the model...\n",
      "saving model now = 2022-07-21 11:22:04.104629\n",
      "just saved\n",
      "i =   1050\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0544\n",
      "i =   1100\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.8391\n",
      "i =   1150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.1215\n",
      "i =   1200\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.0064\n",
      "Evaluate on valid set:  0.8514412416851441\n",
      "This is the best eval res, saving the model...\n",
      "saving model now = 2022-07-21 11:24:18.206835\n",
      "just saved\n",
      "i =   1250\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.1878\n",
      "i =   1300\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.8649\n",
      "i =   1350\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2543\n",
      "i =   1400\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0204\n",
      "Evaluate on valid set:  0.8702882483370288\n",
      "This is the best eval res, saving the model...\n",
      "saving model now = 2022-07-21 11:26:31.151974\n",
      "just saved\n",
      "i =   1450\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0266\n",
      "i =   1500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.2460\n",
      "i =   1550\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0299\n",
      "i =   1600\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0508\n",
      "Evaluate on valid set:  0.8946784922394678\n",
      "This is the best eval res, saving the model...\n",
      "saving model now = 2022-07-21 11:28:44.810724\n",
      "just saved\n",
      "i =   1650\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.3432\n",
      "i =   1700\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 4.3926\n",
      "i =   1750\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0310\n",
      "i =   1800\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0768\n",
      "Evaluate on valid set:  0.8980044345898004\n",
      "This is the best eval res, saving the model...\n",
      "saving model now = 2022-07-21 11:30:56.856064\n",
      "just saved\n",
      "i =   1850\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.1532\n",
      "i =   1900\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.1052\n",
      "i =   1950\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0211\n",
      "i =   2000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0088\n",
      "Evaluate on valid set:  0.8802660753880266\n",
      "i =   2050\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.1052\n",
      "i =   2100\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0356\n",
      "i =   2150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.6638\n",
      "i =   2200\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0100\n",
      "Evaluate on valid set:  0.8968957871396895\n",
      "i =   2250\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0076\n",
      "i =   2300\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0395\n",
      "i =   2350\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0152\n",
      "i =   2400\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0093\n",
      "Evaluate on valid set:  0.9201773835920177\n",
      "This is the best eval res, saving the model...\n",
      "saving model now = 2022-07-21 11:36:27.138410\n",
      "just saved\n",
      "i =   2450\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.1696\n",
      "i =   2500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0081\n",
      "i =   2550\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0123\n",
      "i =   2600\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0583\n",
      "Evaluate on valid set:  0.8957871396895787\n",
      "i =   2650\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.1110\n",
      "i =   2700\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0518\n",
      "i =   2750\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0158\n",
      "i =   2800\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0713\n",
      "Evaluate on valid set:  0.9168514412416852\n",
      "i =   2850\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0226\n",
      "i =   2900\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4850\n",
      "i =   2950\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0174\n",
      "i =   3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.6556\n",
      "Evaluate on valid set:  0.9223946784922394\n",
      "This is the best eval res, saving the model...\n",
      "saving model now = 2022-07-21 11:41:59.704145\n",
      "just saved\n",
      "i =   3050\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0136\n",
      "i =   3100\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0302\n",
      "i =   3150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.5908\n",
      "i =   3200\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0535\n",
      "Evaluate on valid set:  0.9002217294900222\n",
      "i =   3250\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.6368\n",
      "i =   3300\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0173\n",
      "i =   3350\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0254\n",
      "i =   3400\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.1281\n",
      "Evaluate on valid set:  0.88470066518847\n",
      "i =   3450\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0150\n",
      "i =   3500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0976\n",
      "i =   3550\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0093\n",
      "i =   3600\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0152\n",
      "Evaluate on valid set:  0.9356984478935698\n",
      "This is the best eval res, saving the model...\n",
      "saving model now = 2022-07-21 11:47:29.094172\n",
      "just saved\n",
      "37.093204379081726\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "pNet.train(x_train,y_train,x_test,y_test, epochs=1, saveModel=True, model_name=\"test_hotel\")\n",
    "execution_time = (time.time() - start_time) / 60\n",
    "print(execution_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model testing (from saved model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to work with the model when the validation accuracy was the best.\n",
    "Therefore, we load the saved model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[db] model.input =  KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.string, name='input_1'), name='input_1', description=\"created by layer 'input_1'\")\n",
      "[db] protoLayerName =  proto_layer\n",
      "[db] protoLayer =  <protoryNet.ProtoryNet.createModel.<locals>.prototypeLayer object at 0x7f7adc1e4a10>\n",
      "[db] protoLayer.output =  (<KerasTensor: shape=(1, None, 10) dtype=float32 (created by layer 'proto_layer')>, <KerasTensor: shape=(10, 512) dtype=float32 (created by layer 'proto_layer')>)\n",
      "[db] distanceLayer.output =  KerasTensor(type_spec=TensorSpec(shape=(1, None, 10), dtype=tf.float32, name=None), name='distance_layer/PartitionedCall:0', description=\"created by layer 'distance_layer'\")\n",
      "Model: \"custom_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None,)]                 0         \n",
      "                                                                 \n",
      " keras_layer (KerasLayer)    (None, 512)               256797824 \n",
      "                                                                 \n",
      " tf.expand_dims (TFOpLambda)  (1, None, 512)           0         \n",
      "                                                                 \n",
      " proto_layer (prototypeLayer  ((1, None, 10),          5120      \n",
      " )                            (10, 512))                         \n",
      "                                                                 \n",
      " distance_layer (distanceLay  (1, None, 10)            0         \n",
      " er)                                                             \n",
      "                                                                 \n",
      " lstm (LSTM)                 [(1, None, 128),          71168     \n",
      "                              (1, 128),                          \n",
      "                              (1, 128)]                          \n",
      "                                                                 \n",
      " tf.__operators__.getitem (S  (1, 128)                 0         \n",
      " licingOpLambda)                                                 \n",
      "                                                                 \n",
      " dense (Dense)               (1, 1)                    129       \n",
      "                                                                 \n",
      " tf.compat.v1.squeeze (TFOpL  (1,)                     0         \n",
      " ambda)                                                          \n",
      "                                                                 \n",
      " model (Functional)          ((1, None, 10),           256802944 \n",
      "                              (10, 512))                         \n",
      "                                                                 \n",
      " model_1 (Functional)        (1, None, 10)             256802944 \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 256,874,241\n",
      "Trainable params: 256,874,241\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nprototypes = 10\n",
    "model_path = 'test_hotel.h5'\n",
    "\n",
    "pNet_saved = ProtoryNet()\n",
    "model = pNet_saved.createModel(np.zeros((nprototypes, 512)), nprototypes)\n",
    "model.load_weights(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the embedder is trained along which the model, we cannot use anymore the embeddings from Google Universal Encoder. \n",
    "We need to use the fine-tuned embedder of the model. \n",
    "We can access it through ```.embed()```.\n",
    "We embed the sentences using the new embedder.\n",
    "We need these embedded sentences to later see the prototypes of the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sentences_embedded = pNet_saved.embed(sample_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test accuracy is approximately 93%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.009236685,\n",
       "  0.8359412,\n",
       "  0.98266166,\n",
       "  0.9742343,\n",
       "  0.030007662,\n",
       "  0.97888786,\n",
       "  0.26315978,\n",
       "  0.085663304,\n",
       "  0.009625662,\n",
       "  0.97489357,\n",
       "  0.9887173,\n",
       "  0.98883736,\n",
       "  0.16210902,\n",
       "  0.9827943,\n",
       "  0.010352292,\n",
       "  0.97174305,\n",
       "  0.9790254,\n",
       "  0.97521985,\n",
       "  0.57795393,\n",
       "  0.9856171,\n",
       "  0.9535169,\n",
       "  0.99347126,\n",
       "  0.26618475,\n",
       "  0.63590795,\n",
       "  0.6674057,\n",
       "  0.9797632,\n",
       "  0.07994812,\n",
       "  0.9860044,\n",
       "  0.9936752,\n",
       "  0.029118944,\n",
       "  0.99273694,\n",
       "  0.03949093,\n",
       "  0.96651024,\n",
       "  0.042999916,\n",
       "  0.9696063,\n",
       "  0.9711973,\n",
       "  0.89880747,\n",
       "  0.0654446,\n",
       "  0.45315576,\n",
       "  0.9792458,\n",
       "  0.2899294,\n",
       "  0.9675286,\n",
       "  0.06526422,\n",
       "  0.966731,\n",
       "  0.9899165,\n",
       "  0.009109211,\n",
       "  0.0312802,\n",
       "  0.98854095,\n",
       "  0.2522606,\n",
       "  0.069065206,\n",
       "  0.48740974,\n",
       "  0.9804944,\n",
       "  0.9894852,\n",
       "  0.9170779,\n",
       "  0.6747042,\n",
       "  0.41735515,\n",
       "  0.04179582,\n",
       "  0.9721919,\n",
       "  0.9882619,\n",
       "  0.94456625,\n",
       "  0.009794364,\n",
       "  0.012702928,\n",
       "  0.22117573,\n",
       "  0.6056591,\n",
       "  0.9825514,\n",
       "  0.9683224,\n",
       "  0.07020599,\n",
       "  0.57513773,\n",
       "  0.06275198,\n",
       "  0.9929115,\n",
       "  0.576648,\n",
       "  0.78463197,\n",
       "  0.033086147,\n",
       "  0.9933698,\n",
       "  0.9709542,\n",
       "  0.20302822,\n",
       "  0.8257769,\n",
       "  0.01310654,\n",
       "  0.98742783,\n",
       "  0.992634,\n",
       "  0.017571613,\n",
       "  0.08880428,\n",
       "  0.04289545,\n",
       "  0.13882586,\n",
       "  0.9924614,\n",
       "  0.086468175,\n",
       "  0.9719082,\n",
       "  0.013912265,\n",
       "  0.06878906,\n",
       "  0.74373394,\n",
       "  0.98490715,\n",
       "  0.040779077,\n",
       "  0.047634143,\n",
       "  0.9673561,\n",
       "  0.95797753,\n",
       "  0.9004152,\n",
       "  0.025324365,\n",
       "  0.9890717,\n",
       "  0.97062194,\n",
       "  0.09980968,\n",
       "  0.9464342,\n",
       "  0.017191961,\n",
       "  0.012528557,\n",
       "  0.9786847,\n",
       "  0.25470483,\n",
       "  0.99051344,\n",
       "  0.8134852,\n",
       "  0.96620667,\n",
       "  0.015519989,\n",
       "  0.042482257,\n",
       "  0.82805526,\n",
       "  0.9827323,\n",
       "  0.059557784,\n",
       "  0.9167453,\n",
       "  0.9902276,\n",
       "  0.009702162,\n",
       "  0.9533363,\n",
       "  0.98907185,\n",
       "  0.013050108,\n",
       "  0.029387897,\n",
       "  0.98777616,\n",
       "  0.98052555,\n",
       "  0.013262089,\n",
       "  0.0971755,\n",
       "  0.9926778,\n",
       "  0.012489205,\n",
       "  0.46231,\n",
       "  0.062506594,\n",
       "  0.9879671,\n",
       "  0.9652147,\n",
       "  0.9879169,\n",
       "  0.97238207,\n",
       "  0.06264253,\n",
       "  0.9811152,\n",
       "  0.9299693,\n",
       "  0.012877015,\n",
       "  0.37706095,\n",
       "  0.0707705,\n",
       "  0.07989558,\n",
       "  0.012906961,\n",
       "  0.99003685,\n",
       "  0.9348358,\n",
       "  0.9644867,\n",
       "  0.051734615,\n",
       "  0.29030913,\n",
       "  0.10323106,\n",
       "  0.13236463,\n",
       "  0.96914667,\n",
       "  0.9854769,\n",
       "  0.08465897,\n",
       "  0.9834064,\n",
       "  0.25784275,\n",
       "  0.505184,\n",
       "  0.970941,\n",
       "  0.8665888,\n",
       "  0.99027747,\n",
       "  0.97658074,\n",
       "  0.009020142,\n",
       "  0.45574394,\n",
       "  0.9942206,\n",
       "  0.9620107,\n",
       "  0.9898925,\n",
       "  0.2553269,\n",
       "  0.020462207,\n",
       "  0.019209376,\n",
       "  0.9869212,\n",
       "  0.20687783,\n",
       "  0.05216707,\n",
       "  0.82577384,\n",
       "  0.20687783,\n",
       "  0.04074244,\n",
       "  0.012538956,\n",
       "  0.034887806,\n",
       "  0.9701404,\n",
       "  0.9714328,\n",
       "  0.009880598,\n",
       "  0.9877465,\n",
       "  0.2678791,\n",
       "  0.06861624,\n",
       "  0.99304634,\n",
       "  0.043825362,\n",
       "  0.9492479,\n",
       "  0.9945433,\n",
       "  0.98819447,\n",
       "  0.14508723,\n",
       "  0.07627358,\n",
       "  0.9923229,\n",
       "  0.029985078,\n",
       "  0.97291833,\n",
       "  0.013320954,\n",
       "  0.01265228,\n",
       "  0.77087384,\n",
       "  0.5131221,\n",
       "  0.012183976,\n",
       "  0.9898039,\n",
       "  0.013235251,\n",
       "  0.83427125,\n",
       "  0.94195545,\n",
       "  0.9326993,\n",
       "  0.021212762,\n",
       "  0.009711012,\n",
       "  0.2613663,\n",
       "  0.8275316,\n",
       "  0.021678744,\n",
       "  0.27990147,\n",
       "  0.94129264,\n",
       "  0.14524144,\n",
       "  0.99294925,\n",
       "  0.9062014,\n",
       "  0.28506836,\n",
       "  0.009420782,\n",
       "  0.32714024,\n",
       "  0.261888,\n",
       "  0.67089033,\n",
       "  0.9861243,\n",
       "  0.97029144,\n",
       "  0.97377205,\n",
       "  0.26952997,\n",
       "  0.0122405365,\n",
       "  0.029953208,\n",
       "  0.14528261,\n",
       "  0.99053955,\n",
       "  0.08803878,\n",
       "  0.08631917,\n",
       "  0.029666571,\n",
       "  0.96241397,\n",
       "  0.8743025,\n",
       "  0.46392334,\n",
       "  0.0091611175,\n",
       "  0.055061355,\n",
       "  0.99337256,\n",
       "  0.009050456,\n",
       "  0.2517457,\n",
       "  0.98987925,\n",
       "  0.009189743,\n",
       "  0.25140482,\n",
       "  0.93249243,\n",
       "  0.99277544,\n",
       "  0.9855773,\n",
       "  0.045559853,\n",
       "  0.96683514,\n",
       "  0.22567981,\n",
       "  0.29581264,\n",
       "  0.012135417,\n",
       "  0.012409442,\n",
       "  0.9675051,\n",
       "  0.64661914,\n",
       "  0.023898639,\n",
       "  0.9922127,\n",
       "  0.02713044,\n",
       "  0.9559654,\n",
       "  0.058659986,\n",
       "  0.96597123,\n",
       "  0.95514613,\n",
       "  0.13435015,\n",
       "  0.85601485,\n",
       "  0.96093565,\n",
       "  0.94724107,\n",
       "  0.9854585,\n",
       "  0.2188268,\n",
       "  0.8864053,\n",
       "  0.98824304,\n",
       "  0.009287565,\n",
       "  0.013857587,\n",
       "  0.01298089,\n",
       "  0.9879615,\n",
       "  0.9844892,\n",
       "  0.062637046,\n",
       "  0.8169438,\n",
       "  0.82494503,\n",
       "  0.10235212,\n",
       "  0.2908421,\n",
       "  0.33303162,\n",
       "  0.19542943,\n",
       "  0.9218921,\n",
       "  0.012941062,\n",
       "  0.58278245,\n",
       "  0.9873339,\n",
       "  0.46096778,\n",
       "  0.084775515,\n",
       "  0.022675088,\n",
       "  0.9112974,\n",
       "  0.8992162,\n",
       "  0.2597134,\n",
       "  0.9477005,\n",
       "  0.9666658,\n",
       "  0.021307636,\n",
       "  0.9804285,\n",
       "  0.9914888,\n",
       "  0.2667161,\n",
       "  0.9681501,\n",
       "  0.03232883,\n",
       "  0.0095645515,\n",
       "  0.95730966,\n",
       "  0.909377,\n",
       "  0.984143,\n",
       "  0.97786146,\n",
       "  0.044993907,\n",
       "  0.9459047,\n",
       "  0.016757112,\n",
       "  0.99290776,\n",
       "  0.01183877,\n",
       "  0.008717135,\n",
       "  0.8839244,\n",
       "  0.08818667,\n",
       "  0.9819572,\n",
       "  0.1763678,\n",
       "  0.9298681,\n",
       "  0.30803284,\n",
       "  0.9762248,\n",
       "  0.2474811,\n",
       "  0.30562544,\n",
       "  0.84016836,\n",
       "  0.9847136,\n",
       "  0.97217363,\n",
       "  0.98826677,\n",
       "  0.98893726,\n",
       "  0.97144115,\n",
       "  0.9940713,\n",
       "  0.9705932,\n",
       "  0.98138404,\n",
       "  0.033457845,\n",
       "  0.95073867,\n",
       "  0.025247108,\n",
       "  0.99379987,\n",
       "  0.9777259,\n",
       "  0.9771451,\n",
       "  0.23064935,\n",
       "  0.2196999,\n",
       "  0.08965446,\n",
       "  0.027276793,\n",
       "  0.13822006,\n",
       "  0.9872362,\n",
       "  0.47424406,\n",
       "  0.015103708,\n",
       "  0.027912617,\n",
       "  0.056467034,\n",
       "  0.82735664,\n",
       "  0.08784048,\n",
       "  0.030043911,\n",
       "  0.15094861,\n",
       "  0.35592195,\n",
       "  0.26004422,\n",
       "  0.5184676,\n",
       "  0.504888,\n",
       "  0.8211025,\n",
       "  0.025787415,\n",
       "  0.51256806,\n",
       "  0.042375527,\n",
       "  0.97787523,\n",
       "  0.9558032,\n",
       "  0.9748355,\n",
       "  0.9607579,\n",
       "  0.9854137,\n",
       "  0.28574833,\n",
       "  0.09165502,\n",
       "  0.9942374,\n",
       "  0.012966559,\n",
       "  0.988304,\n",
       "  0.95990515,\n",
       "  0.06419582,\n",
       "  0.008683412,\n",
       "  0.013263531,\n",
       "  0.9862294,\n",
       "  0.99303836,\n",
       "  0.9308034,\n",
       "  0.012351302,\n",
       "  0.10689819,\n",
       "  0.97996485,\n",
       "  0.016209085,\n",
       "  0.9929951,\n",
       "  0.9897619,\n",
       "  0.03144168,\n",
       "  0.05087304,\n",
       "  0.013159107,\n",
       "  0.9521932,\n",
       "  0.087292224,\n",
       "  0.98893344,\n",
       "  0.98462176,\n",
       "  0.3423301,\n",
       "  0.90860516,\n",
       "  0.9938176,\n",
       "  0.928095,\n",
       "  0.9887832,\n",
       "  0.03251496,\n",
       "  0.2763611,\n",
       "  0.9869664,\n",
       "  0.104766324,\n",
       "  0.035425,\n",
       "  0.9830498,\n",
       "  0.9751926,\n",
       "  0.9719358,\n",
       "  0.99063665,\n",
       "  0.9380807,\n",
       "  0.67061746,\n",
       "  0.027880032,\n",
       "  0.9805925,\n",
       "  0.009207525,\n",
       "  0.5830928,\n",
       "  0.95089626,\n",
       "  0.03093405,\n",
       "  0.96766293,\n",
       "  0.9927683,\n",
       "  0.9917469,\n",
       "  0.1564113,\n",
       "  0.11472586,\n",
       "  0.9834067,\n",
       "  0.5091101,\n",
       "  0.2616837,\n",
       "  0.36639214,\n",
       "  0.9661697,\n",
       "  0.013625654,\n",
       "  0.91866463,\n",
       "  0.008750656,\n",
       "  0.03149724,\n",
       "  0.9942964,\n",
       "  0.83248067,\n",
       "  0.47265378,\n",
       "  0.98998535,\n",
       "  0.99474216,\n",
       "  0.9741799,\n",
       "  0.09413632,\n",
       "  0.02784103,\n",
       "  0.97949344,\n",
       "  0.990549,\n",
       "  0.98687416,\n",
       "  0.98729056,\n",
       "  0.059959155,\n",
       "  0.022560941,\n",
       "  0.009431731,\n",
       "  0.092112705,\n",
       "  0.02982958,\n",
       "  0.8190341,\n",
       "  0.6184871,\n",
       "  0.14908667,\n",
       "  0.98314226,\n",
       "  0.8211873,\n",
       "  0.9940844,\n",
       "  0.06482244,\n",
       "  0.013485671,\n",
       "  0.97730184,\n",
       "  0.8603495,\n",
       "  0.91705775,\n",
       "  0.96334445,\n",
       "  0.03233341,\n",
       "  0.8839473,\n",
       "  0.98263794,\n",
       "  0.23392957,\n",
       "  0.31786948,\n",
       "  0.98910207,\n",
       "  0.91205215,\n",
       "  0.13492863,\n",
       "  0.9479166,\n",
       "  0.9834382,\n",
       "  0.99052924,\n",
       "  0.8699503,\n",
       "  0.97529954,\n",
       "  0.058811672,\n",
       "  0.5177056,\n",
       "  0.6913106,\n",
       "  0.99059486,\n",
       "  0.030008817,\n",
       "  0.028207455,\n",
       "  0.951285,\n",
       "  0.0100586815,\n",
       "  0.030958489,\n",
       "  0.09335326,\n",
       "  0.96685946,\n",
       "  0.012860381,\n",
       "  0.40087762,\n",
       "  0.91384923,\n",
       "  0.03616304,\n",
       "  0.9559521,\n",
       "  0.02392105,\n",
       "  0.27176565,\n",
       "  0.017319992,\n",
       "  0.99286216,\n",
       "  0.059110217,\n",
       "  0.8792985,\n",
       "  0.65352535,\n",
       "  0.94916487,\n",
       "  0.47122124,\n",
       "  0.61411816,\n",
       "  0.95299566,\n",
       "  0.03335376,\n",
       "  0.9857889,\n",
       "  0.14442244,\n",
       "  0.9044098,\n",
       "  0.019838572,\n",
       "  0.76357657,\n",
       "  0.028369544,\n",
       "  0.9741513,\n",
       "  0.9836023,\n",
       "  0.02927905,\n",
       "  0.9896673,\n",
       "  0.013386795,\n",
       "  0.46365482,\n",
       "  0.99223846,\n",
       "  0.16246489,\n",
       "  0.95715106,\n",
       "  0.984233,\n",
       "  0.08856354,\n",
       "  0.030351575,\n",
       "  0.9897503,\n",
       "  0.1938442,\n",
       "  0.99284464,\n",
       "  0.8436324,\n",
       "  0.2734368,\n",
       "  0.9462014,\n",
       "  0.32571363,\n",
       "  0.98570037,\n",
       "  0.8842363,\n",
       "  0.9544625,\n",
       "  0.18107247,\n",
       "  0.9866089,\n",
       "  0.009593686,\n",
       "  0.9288166,\n",
       "  0.016788723,\n",
       "  0.935301,\n",
       "  0.020503564,\n",
       "  0.99287295,\n",
       "  0.8247878,\n",
       "  0.9583178,\n",
       "  0.012832107,\n",
       "  0.04289541,\n",
       "  0.37883157,\n",
       "  0.9908949,\n",
       "  0.95455444,\n",
       "  0.030578855,\n",
       "  0.058791064,\n",
       "  0.9359833,\n",
       "  0.009316154,\n",
       "  0.41411826,\n",
       "  0.95335674,\n",
       "  0.028838692,\n",
       "  0.75117993,\n",
       "  0.072792515,\n",
       "  0.80841625,\n",
       "  0.9785347,\n",
       "  0.993558,\n",
       "  0.05214854,\n",
       "  0.86896324,\n",
       "  0.25538108,\n",
       "  0.99201185,\n",
       "  0.06430972,\n",
       "  0.9898324,\n",
       "  0.031741492,\n",
       "  0.029982207,\n",
       "  0.9093198,\n",
       "  0.03409942,\n",
       "  0.9310232,\n",
       "  0.25972205,\n",
       "  0.10006671,\n",
       "  0.012979559,\n",
       "  0.985485,\n",
       "  0.03138939,\n",
       "  0.96667486,\n",
       "  0.98497033,\n",
       "  0.99042225,\n",
       "  0.9526775,\n",
       "  0.23779625,\n",
       "  0.874548,\n",
       "  0.101617455,\n",
       "  0.9368077,\n",
       "  0.8173971,\n",
       "  0.01135274,\n",
       "  0.036289796,\n",
       "  0.038993597,\n",
       "  0.029657278,\n",
       "  0.9843866,\n",
       "  0.7184715,\n",
       "  0.98508584,\n",
       "  0.14326875,\n",
       "  0.9890942,\n",
       "  0.99119204,\n",
       "  0.9899967,\n",
       "  0.074574985,\n",
       "  0.99357295,\n",
       "  0.439629,\n",
       "  0.5217765,\n",
       "  0.7748275,\n",
       "  0.05961713,\n",
       "  0.9933154,\n",
       "  0.7606229,\n",
       "  0.98932487,\n",
       "  0.082531236,\n",
       "  0.009805603,\n",
       "  0.6070797,\n",
       "  0.06343487,\n",
       "  0.43304026,\n",
       "  0.98062503,\n",
       "  0.9758337,\n",
       "  0.986598,\n",
       "  0.029674254,\n",
       "  0.04413576,\n",
       "  0.9713984,\n",
       "  0.7919513,\n",
       "  0.9827806,\n",
       "  0.95239234,\n",
       "  0.52174383,\n",
       "  0.05675988,\n",
       "  0.031270348,\n",
       "  0.46067137,\n",
       "  0.9784515,\n",
       "  0.9719135,\n",
       "  0.10654099,\n",
       "  0.13221134,\n",
       "  0.031056901,\n",
       "  0.09189072,\n",
       "  0.95386714,\n",
       "  0.25024363,\n",
       "  0.92585987,\n",
       "  0.05842834,\n",
       "  0.25769237,\n",
       "  0.03392055,\n",
       "  0.9943453,\n",
       "  0.26612735,\n",
       "  0.124351576,\n",
       "  0.8259829,\n",
       "  0.6652144,\n",
       "  0.89486325,\n",
       "  0.046921857,\n",
       "  0.038267236,\n",
       "  0.027526047,\n",
       "  0.9891144,\n",
       "  0.95268786,\n",
       "  0.27944154,\n",
       "  0.5086707,\n",
       "  0.037501603,\n",
       "  0.99429804,\n",
       "  0.039361916,\n",
       "  0.9916265,\n",
       "  0.030352741,\n",
       "  0.7857279,\n",
       "  0.032546956,\n",
       "  0.013926581,\n",
       "  0.019755874,\n",
       "  0.9812154,\n",
       "  0.9258962,\n",
       "  0.2569297,\n",
       "  0.028971601,\n",
       "  0.99193114,\n",
       "  0.9905785,\n",
       "  0.14631897,\n",
       "  0.92482436,\n",
       "  0.9684895,\n",
       "  0.7331497,\n",
       "  0.06705268,\n",
       "  0.7066558,\n",
       "  0.012928862,\n",
       "  0.9891265,\n",
       "  0.06536085,\n",
       "  0.98023224,\n",
       "  0.087911695,\n",
       "  0.022605704,\n",
       "  0.013130845,\n",
       "  0.114984795,\n",
       "  0.95989865,\n",
       "  0.36727694,\n",
       "  0.9917303,\n",
       "  0.98202914,\n",
       "  0.2929386,\n",
       "  0.032547932,\n",
       "  0.9919395,\n",
       "  0.25371268,\n",
       "  0.031311397,\n",
       "  0.36704725,\n",
       "  0.9606528,\n",
       "  0.19627891,\n",
       "  0.1518092,\n",
       "  0.13064441,\n",
       "  0.6912255,\n",
       "  0.8548071,\n",
       "  0.3072496,\n",
       "  0.9854388,\n",
       "  0.9668169,\n",
       "  0.99220145,\n",
       "  0.96815723,\n",
       "  0.95120215,\n",
       "  0.02969262,\n",
       "  0.0709395,\n",
       "  0.9337587,\n",
       "  0.020847702,\n",
       "  0.012256298,\n",
       "  0.09254911,\n",
       "  0.9788674,\n",
       "  0.008502,\n",
       "  0.9885731,\n",
       "  0.012875275,\n",
       "  0.009540884,\n",
       "  0.02871427,\n",
       "  0.01268807,\n",
       "  0.054163784,\n",
       "  0.9868015,\n",
       "  0.98806363,\n",
       "  0.92968744,\n",
       "  0.9922496,\n",
       "  0.8850423,\n",
       "  0.037072673,\n",
       "  0.84101415,\n",
       "  0.009960206,\n",
       "  0.15424865,\n",
       "  0.97679645,\n",
       "  0.8213195,\n",
       "  0.44418943,\n",
       "  0.5067689,\n",
       "  0.029260516,\n",
       "  0.95184124,\n",
       "  0.012221135,\n",
       "  0.068003386,\n",
       "  0.9941393,\n",
       "  0.06203508,\n",
       "  0.027290156,\n",
       "  0.9937536,\n",
       "  0.13465457,\n",
       "  0.107744396,\n",
       "  0.9869871,\n",
       "  0.981122,\n",
       "  0.10058068,\n",
       "  0.9947246,\n",
       "  0.3134758,\n",
       "  0.11948926,\n",
       "  0.96939474,\n",
       "  0.039846458,\n",
       "  0.027651886,\n",
       "  0.05181765,\n",
       "  0.074328996,\n",
       "  0.84943974,\n",
       "  0.031051593,\n",
       "  0.20979309,\n",
       "  0.06497067,\n",
       "  0.98808974,\n",
       "  0.98552805,\n",
       "  0.77021194,\n",
       "  0.98817396,\n",
       "  0.0090290895,\n",
       "  0.1742358,\n",
       "  0.012815373,\n",
       "  0.97365177,\n",
       "  0.009554877,\n",
       "  0.022815974,\n",
       "  0.83483374,\n",
       "  0.012817305,\n",
       "  0.031304196,\n",
       "  0.028177656,\n",
       "  0.60511273,\n",
       "  0.94252574,\n",
       "  0.123175554,\n",
       "  0.9807945,\n",
       "  0.95934594,\n",
       "  0.048340805,\n",
       "  0.96056145,\n",
       "  0.778033,\n",
       "  0.97051483,\n",
       "  0.9400328,\n",
       "  0.9797181,\n",
       "  0.76393586,\n",
       "  0.051387563,\n",
       "  0.98422205,\n",
       "  0.87820345,\n",
       "  0.009326163,\n",
       "  0.96801424,\n",
       "  0.94045645,\n",
       "  0.96790266,\n",
       "  0.70992494,\n",
       "  0.067016445,\n",
       "  0.05423685,\n",
       "  0.012739892,\n",
       "  0.80906963,\n",
       "  0.09441673,\n",
       "  0.5108804,\n",
       "  0.9891158,\n",
       "  0.08792086,\n",
       "  0.95417506,\n",
       "  0.49126998,\n",
       "  0.21193494,\n",
       "  0.02804698,\n",
       "  0.9884283,\n",
       "  0.028463751,\n",
       "  0.049585134,\n",
       "  0.8751923,\n",
       "  0.10143145,\n",
       "  0.26183406,\n",
       "  0.9927999,\n",
       "  0.009202567,\n",
       "  0.06858338,\n",
       "  0.009154908,\n",
       "  0.009508002,\n",
       "  0.0675384,\n",
       "  0.9821874,\n",
       "  0.009690984,\n",
       "  0.5133857,\n",
       "  0.921311,\n",
       "  0.73784196,\n",
       "  0.092119604,\n",
       "  0.26273102,\n",
       "  0.97657084,\n",
       "  0.2641109,\n",
       "  0.0907032,\n",
       "  0.98545295,\n",
       "  0.9902491,\n",
       "  0.8674519,\n",
       "  0.7479584,\n",
       "  0.46838328,\n",
       "  0.99473816,\n",
       "  0.009194402,\n",
       "  0.03749076,\n",
       "  0.95528674,\n",
       "  0.9886008,\n",
       "  0.91500795,\n",
       "  0.98725885,\n",
       "  0.035652623,\n",
       "  0.97543406,\n",
       "  0.9740021,\n",
       "  0.9610257,\n",
       "  0.55232966,\n",
       "  0.8796463,\n",
       "  0.94415337,\n",
       "  0.26360628,\n",
       "  0.03263525,\n",
       "  0.06761168,\n",
       "  0.051902596,\n",
       "  0.012353879,\n",
       "  0.28006178,\n",
       "  0.9781537,\n",
       "  0.90506005,\n",
       "  0.24148601,\n",
       "  0.9023294,\n",
       "  0.012536234,\n",
       "  0.058638558,\n",
       "  0.1040093,\n",
       "  0.9882414,\n",
       "  0.091016665,\n",
       "  0.9897155,\n",
       "  0.3939587,\n",
       "  0.071017474,\n",
       "  0.10755043,\n",
       "  0.9909608,\n",
       "  0.027695755,\n",
       "  0.16440508,\n",
       "  0.009769902,\n",
       "  0.009531246,\n",
       "  0.99316496,\n",
       "  0.98981994,\n",
       "  0.03708507,\n",
       "  0.9855903,\n",
       "  0.9880527,\n",
       "  0.9258972,\n",
       "  0.6810157,\n",
       "  0.010265593,\n",
       "  0.97163504,\n",
       "  0.83597577,\n",
       "  0.10499712,\n",
       "  0.28682268,\n",
       "  0.2801108,\n",
       "  0.06633962,\n",
       "  0.86362135,\n",
       "  0.028699435,\n",
       "  0.028223356,\n",
       "  0.012790435,\n",
       "  0.08768423,\n",
       "  0.983529,\n",
       "  0.95764434,\n",
       "  0.030483264,\n",
       "  0.9932202,\n",
       "  0.01200502,\n",
       "  0.98884064,\n",
       "  0.055332582,\n",
       "  0.99319035,\n",
       "  0.99322444,\n",
       "  0.08582053,\n",
       "  0.9929026,\n",
       "  0.78108406,\n",
       "  0.50572777,\n",
       "  0.04603415,\n",
       "  0.5123927,\n",
       "  0.98921156,\n",
       "  0.9926224,\n",
       "  0.9504149,\n",
       "  0.20874918,\n",
       "  0.9945857,\n",
       "  0.012309137,\n",
       "  0.91430795,\n",
       "  0.99462575,\n",
       "  0.98619765,\n",
       "  0.95243776,\n",
       "  0.04394064,\n",
       "  0.98930466,\n",
       "  0.5472647,\n",
       "  0.012588161,\n",
       "  0.04682101,\n",
       "  0.9802147,\n",
       "  0.012347946,\n",
       "  0.18099074,\n",
       "  0.43922228,\n",
       "  0.029201465,\n",
       "  0.029824447,\n",
       "  0.012967432,\n",
       "  0.9863733,\n",
       "  0.9908331,\n",
       "  0.9885262,\n",
       "  0.9889798],\n",
       " 0.9356984478935698)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pNet_saved.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the prototypes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: \"I'd stay here again for sure\",\n",
       " 1: 'Never was able to get a shuttle the entire time we were there',\n",
       " 2: \"It was my first stay in a kimpton hotel and now I don't want to stay anywhere else\",\n",
       " 3: 'Was a small hotel which was fine for us',\n",
       " 4: \"I would have given this hotel a 5 star but we didn't like the parking situation\",\n",
       " 5: 'I am happy to hear that you enjoyed our great location',\n",
       " 6: 'We stop here often if we cannot get a decent price in a WDW resort',\n",
       " 7: 'And if you need pharmacy or coffee fix, they are all along the Main St right outside the hotel',\n",
       " 8: 'More',\n",
       " 9: 'We chose Hotel Abri because it was over 100 less than a place across the street'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prototypes = pNet_saved.showPrototypes(sample_sentences, sample_sentences_embedded, nprototypes, printOutput=False, return_prototypes = True)\n",
    "prototypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, the model correctly classifies a positive review.\n",
    "The prediction is 0.66, since is it above 0.5, the prediction is \"positive review\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.6664621], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testS = [\"Generally I like the hotel and will come back\",\n",
    "         \"It's a small hotel\",\n",
    "         \"The room is nice, clean and suitable for a nice stay however\",\n",
    "         \"It's one of the best in the area\"]\n",
    "pNet_saved.predict(testS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we see the prototype associated to each sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I am happy to hear that you enjoyed our great location', 'Was a small hotel which was fine for us', 'I am happy to hear that you enjoyed our great location', 'Was a small hotel which was fine for us']\n"
     ]
    }
   ],
   "source": [
    "trajectory = pNet_saved.showTrajectory(testS, sample_sentences, sample_sentences_embedded)\n",
    "print(trajectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_trajectory(list_of_sentences):\n",
    "    '''\n",
    "    given a list of sentences (usually a list of prototypes), it returns the prediction for each of them\n",
    "    '''\n",
    "    pred = []\n",
    "    for prot in list_of_sentences:\n",
    "        pred.append(pNet_saved.predict([prot])[0])\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scores associated to each prototype are shown below.  \n",
    "\n",
    "**Note that all prototypes by their own would give a positive score, that is, the prediction for each prototype would be \"positive review\", nevertheless the model classifies correctly negative reviews.**\n",
    "If the model was trully only mapping the sentences to the prototypes then taking decisions based on them the predictions would be always \"positive review\". \n",
    "Therefore, after mapping each sentence to the prototypes, the model is still taking some decisions, which remain occluded in the layers after the prototype layer. \n",
    "This indicates that protorynet is not as transparent as their authors claim it to be. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7718854,\n",
       " 0.70234185,\n",
       " 0.70097613,\n",
       " 0.77185166,\n",
       " 0.77171296,\n",
       " 0.77266157,\n",
       " 0.7023217,\n",
       " 0.77139384,\n",
       " 0.69554263,\n",
       " 0.7715117]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_trajectory(prototypes.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.77266157, 0.77185166, 0.77266157, 0.77185166]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_trajectory(trajectory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples where the model fails at explainability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See how the model correctly classifies a negative review:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Share your room with roach or bug', ' Roach in the room but the staff said its just a bug not a roach, like that made it any better', ' Big hole in the bathroom wall were this bug/roach came out of', ' Wonder what other rodent will come out of the wall', 'Thank you for providing us with your feedback', ' I would like to apologize for any of the inconveniences you may have experienced during your time with us', ' I wish that I had been notified of your concerns before you had checked out and I would like to apologize on behalf of our staff']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.00923669], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testS = x_test[0]\n",
    "print(testS)\n",
    "pNet_saved.predict(testS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nevertheless, the prototypes associated to each sentences give no information about why it was classified as negative. \n",
    "Moreover, all prototypes are the same. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['More', 'More', 'More', 'More', 'More', 'More', 'More']\n"
     ]
    }
   ],
   "source": [
    "# Prototypes related to each sentence\n",
    "trajectory = pNet_saved.showTrajectory(testS, sample_sentences, sample_sentences_embedded)\n",
    "print(trajectory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this other example, the model correctly classifies a negative review, but one more the prototypes give little explanaitions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Worst ever ', ' Room was nasty falling apart poorly kept up it ended up being the worst stay ever if it wasnt the only thing available for a big concert weekend we would of canceled ', 'the door had electrical tape covering up around the door knob , the locks did not work, we only had one light that worked,the microwave was covered in', ' More']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.0856633], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testS = x_test[7]\n",
    "print(testS)\n",
    "pNet_saved.predict(testS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['More', 'More', 'More', 'More']\n"
     ]
    }
   ],
   "source": [
    "trajectory = pNet_saved.showTrajectory(testS, sample_sentences, sample_sentences_embedded)\n",
    "print(trajectory)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ProtoryNet_example.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "bcc88a5c2b6accdcaf39c87a931cb715cc1ab684beb32819a99a5a377f971b8d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
